{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "y3LPmLWtY_wG",
        "outputId": "9aebaa27-cd39-44eb-a6e0-2b95701f601b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dd5cbdb5-2ca4-4c27-987f-c2da78f97cb8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dd5cbdb5-2ca4-4c27-987f-c2da78f97cb8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Newly_Adjusted_Amazon-like_Dataset_with_Random_Rating_Distribution.csv to Newly_Adjusted_Amazon-like_Dataset_with_Random_Rating_Distribution (1).csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# Upload the dataset\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(list(uploaded.keys())[0], index_col=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Count the total number of users\n",
        "Tnu = df.shape[0]\n",
        "\n",
        "# Step 4: Count the total number of items\n",
        "Tni = df.shape[1]\n",
        "\n",
        "print(f\"Total Users (Tnu): {Tnu}\")\n",
        "print(f\"Total Items (Tni): {Tni}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpxntmo_g08a",
        "outputId": "6dcd75b0-287e-4140-be95-a5cee01b6852"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Users (Tnu): 300\n",
            "Total Items (Tni): 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Count the number of ratings for every product\n",
        "ratings_count_per_product = df.notna().sum()\n",
        "\n",
        "print(\"Ratings Count Per Product:\")\n",
        "print(ratings_count_per_product)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeRq8XiGg3k7",
        "outputId": "c4f6dc32-7471-4288-d8dd-d42476bab51f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings Count Per Product:\n",
            "Product_1     203\n",
            "Product_2     212\n",
            "Product_3     210\n",
            "Product_4     223\n",
            "Product_5     211\n",
            "Product_6     212\n",
            "Product_7     216\n",
            "Product_8     197\n",
            "Product_9     204\n",
            "Product_10    226\n",
            "Product_11    210\n",
            "Product_12    229\n",
            "Product_13    218\n",
            "Product_14    206\n",
            "Product_15    220\n",
            "Product_16    205\n",
            "Product_17    224\n",
            "Product_18    210\n",
            "Product_19    221\n",
            "Product_20    207\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 6: Draw the distribution of ratings\n",
        "rating_distribution = df.stack().value_counts()\n",
        "\n",
        "plt.bar(rating_distribution.index.astype(str), rating_distribution.values)\n",
        "plt.title(\"Distribution of Ratings\")\n",
        "plt.xlabel(\"Rating Value\")\n",
        "plt.ylabel(\"Count of Ratings\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "sq3l6luyg54g",
        "outputId": "d4f2acdc-e2da-44a9-b4b9-64875370d2a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the matrix is sparse and calculate sparsity level\n",
        "total_entries = Tnu * Tni\n",
        "non_empty_entries = df.notna().sum().sum()\n",
        "sparsity_level = (1 - non_empty_entries / total_entries) * 100\n",
        "\n",
        "# Check if there is bias and calculate the level of bias\n",
        "bias_measure = rating_distribution[5] / rating_distribution.sum() if 5 in rating_distribution.index else 0\n",
        "\n",
        "print(f\"Sparsity Level: {sparsity_level:.2f}%\")\n",
        "print(f\"Bias Measure (percentage of 5s): {bias_measure:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X763UT22g_A-",
        "outputId": "6874325f-05f8-45c7-85cb-3c8ae20659f8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity Level: 28.93%\n",
            "Bias Measure (percentage of 5s): 0.70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Choose the two lowest-rated items\n",
        "average_ratings = df.mean()\n",
        "lowest_rated_items = average_ratings.nsmallest(2).index.tolist()\n",
        "I1, I2 = lowest_rated_items\n",
        "\n",
        "print(f\"Lowest Rated Items: I1 = {I1}, I2 = {I2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNklpdzBhC2P",
        "outputId": "d4dcd7c1-6b2e-4cb5-cfa2-9a12d9cdf71b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowest Rated Items: I1 = Product_11, I2 = Product_8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Save all results\n",
        "results = {\n",
        "    \"Total_users\": Tnu,\n",
        "    \"Total_items\": Tni,\n",
        "    \"Ratings_count_per_product\": ratings_count_per_product.to_dict(),\n",
        "    \"Sparsity_level\": sparsity_level,\n",
        "    \"Bias_measure\": bias_measure,\n",
        "    \"Lowest_rated_items\": {\"I1\": I1, \"I2\": I2},\n",
        "}\n",
        "\n",
        "print(\"Results:\")\n",
        "print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9zE5yi5hEI1",
        "outputId": "2676b5e8-24ce-4cd8-8ff2-9f960d5e4aba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "{'Total_users': 300, 'Total_items': 20, 'Ratings_count_per_product': {'Product_1': 203, 'Product_2': 212, 'Product_3': 210, 'Product_4': 223, 'Product_5': 211, 'Product_6': 212, 'Product_7': 216, 'Product_8': 197, 'Product_9': 204, 'Product_10': 226, 'Product_11': 210, 'Product_12': 229, 'Product_13': 218, 'Product_14': 206, 'Product_15': 220, 'Product_16': 205, 'Product_17': 224, 'Product_18': 210, 'Product_19': 221, 'Product_20': 207}, 'Sparsity_level': 28.933333333333334, 'Bias_measure': 0.698874296435272, 'Lowest_rated_items': {'I1': 'Product_11', 'I2': 'Product_8'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average rating for each target item (I1 and I2)\n",
        "average_I1 = df[I1].mean()\n",
        "average_I2 = df[I2].mean()\n",
        "\n",
        "print(f\"Average Rating for I1 ({I1}): {average_I1}\")\n",
        "print(f\"Average Rating for I2 ({I2}): {average_I2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGStp5yMhGl2",
        "outputId": "19b49a2e-f6ee-4e5c-d4a4-d1450b1a9f3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Rating for I1 (Product_11): 4.20952380952381\n",
            "Average Rating for I2 (Product_8): 4.213197969543147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace missing values for I1 and I2 with their respective means\n",
        "df[I1].fillna(average_I1, inplace=True)\n",
        "df[I2].fillna(average_I2, inplace=True)\n",
        "\n",
        "print(f\"Unspecified ratings for {I1} and {I2} have been replaced with their mean values.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI4fNn3qlofr",
        "outputId": "c4ae6c87-fea7-4211-80f2-e9efc84dbfad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unspecified ratings for Product_11 and Product_8 have been replaced with their mean values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-51aa2b09cc80>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[I1].fillna(average_I1, inplace=True)\n",
            "<ipython-input-10-51aa2b09cc80>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[I2].fillna(average_I2, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average rating for each item\n",
        "average_ratings = df.mean()\n",
        "\n",
        "print(\"Average Ratings for Each Item:\")\n",
        "print(average_ratings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa1Z_Qctl6wm",
        "outputId": "9be9e1dc-71f8-4e6f-cb4c-2324d19f5750"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Ratings for Each Item:\n",
            "Product_1     4.487685\n",
            "Product_2     4.367925\n",
            "Product_3     4.371429\n",
            "Product_4     4.273543\n",
            "Product_5     4.407583\n",
            "Product_6     4.433962\n",
            "Product_7     4.314815\n",
            "Product_8     4.213198\n",
            "Product_9     4.455882\n",
            "Product_10    4.477876\n",
            "Product_11    4.209524\n",
            "Product_12    4.458515\n",
            "Product_13    4.412844\n",
            "Product_14    4.451456\n",
            "Product_15    4.277273\n",
            "Product_16    4.346341\n",
            "Product_17    4.334821\n",
            "Product_18    4.252381\n",
            "Product_19    4.316742\n",
            "Product_20    4.357488\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the difference between ratings and mean ratings for each item\n",
        "rating_diff = df.sub(average_ratings, axis=1)\n",
        "\n",
        "print(\"Differences Between Ratings and Mean Ratings:\")\n",
        "print(rating_diff)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEH1t8N0mW2Q",
        "outputId": "b5e1d261-1beb-41b0-f104-338e4ddd60bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Differences Between Ratings and Mean Ratings:\n",
            "                    Product_1  Product_2  Product_3  Product_4  Product_5  \\\n",
            "A1GI0U000004ZRJA8   -2.487685  -1.367925        NaN  -3.273543   0.592417   \n",
            "A1GI0U000005ZRJA9    0.512315        NaN        NaN   0.726457        NaN   \n",
            "A1GI0U000006ZRJA10        NaN        NaN        NaN   0.726457        NaN   \n",
            "A1GI0U000007ZRJA11        NaN   0.632075  -1.371429  -1.273543   0.592417   \n",
            "A1GI0U000008ZRJA12        NaN   0.632075   0.628571  -1.273543        NaN   \n",
            "...                       ...        ...        ...        ...        ...   \n",
            "A1GI0U000299ZRJA13  -0.487685        NaN   0.628571   0.726457        NaN   \n",
            "A1GI0U000300ZRJA14        NaN   0.632075        NaN        NaN   0.592417   \n",
            "A1GI0U000301ZRJA15        NaN        NaN  -1.371429        NaN   0.592417   \n",
            "A1GI0U000302ZRJA16   0.512315   0.632075   0.628571   0.726457        NaN   \n",
            "A1GI0U000303ZRJA17        NaN   0.632075  -3.371429   0.726457        NaN   \n",
            "\n",
            "                    Product_6  Product_7     Product_8  Product_9  Product_10  \\\n",
            "A1GI0U000004ZRJA8    0.566038   0.685185 -3.213198e+00  -0.455882    0.522124   \n",
            "A1GI0U000005ZRJA9    0.566038        NaN -1.213198e+00   0.544118    0.522124   \n",
            "A1GI0U000006ZRJA10  -0.433962  -1.314815 -2.131980e-01        NaN   -2.477876   \n",
            "A1GI0U000007ZRJA11  -0.433962   0.685185 -2.131980e-01        NaN    0.522124   \n",
            "A1GI0U000008ZRJA12        NaN  -1.314815  8.881784e-16   0.544118         NaN   \n",
            "...                       ...        ...           ...        ...         ...   \n",
            "A1GI0U000299ZRJA13   0.566038        NaN  8.881784e-16   0.544118    0.522124   \n",
            "A1GI0U000300ZRJA14  -0.433962  -0.314815  7.868020e-01        NaN    0.522124   \n",
            "A1GI0U000301ZRJA15   0.566038   0.685185 -2.131980e-01   0.544118   -0.477876   \n",
            "A1GI0U000302ZRJA16   0.566038   0.685185 -2.213198e+00        NaN   -0.477876   \n",
            "A1GI0U000303ZRJA17   0.566038        NaN  7.868020e-01        NaN    0.522124   \n",
            "\n",
            "                    Product_11  Product_12  Product_13  Product_14  \\\n",
            "A1GI0U000004ZRJA8     0.790476   -0.458515    0.587156    0.548544   \n",
            "A1GI0U000005ZRJA9    -1.209524    0.541485         NaN         NaN   \n",
            "A1GI0U000006ZRJA10    0.000000         NaN    0.587156    0.548544   \n",
            "A1GI0U000007ZRJA11   -1.209524    0.541485    0.587156         NaN   \n",
            "A1GI0U000008ZRJA12    0.790476    0.541485   -0.412844    0.548544   \n",
            "...                        ...         ...         ...         ...   \n",
            "A1GI0U000299ZRJA13    0.000000    0.541485    0.587156   -2.451456   \n",
            "A1GI0U000300ZRJA14   -0.209524    0.541485    0.587156         NaN   \n",
            "A1GI0U000301ZRJA15    0.790476    0.541485    0.587156   -0.451456   \n",
            "A1GI0U000302ZRJA16    0.000000    0.541485         NaN    0.548544   \n",
            "A1GI0U000303ZRJA17    0.000000    0.541485         NaN    0.548544   \n",
            "\n",
            "                    Product_15  Product_16  Product_17  Product_18  \\\n",
            "A1GI0U000004ZRJA8          NaN         NaN   -0.334821    0.747619   \n",
            "A1GI0U000005ZRJA9    -1.277273    0.653659         NaN         NaN   \n",
            "A1GI0U000006ZRJA10         NaN    0.653659    0.665179    0.747619   \n",
            "A1GI0U000007ZRJA11    0.722727   -1.346341    0.665179         NaN   \n",
            "A1GI0U000008ZRJA12    0.722727    0.653659    0.665179         NaN   \n",
            "...                        ...         ...         ...         ...   \n",
            "A1GI0U000299ZRJA13         NaN         NaN    0.665179   -1.252381   \n",
            "A1GI0U000300ZRJA14    0.722727   -0.346341    0.665179   -1.252381   \n",
            "A1GI0U000301ZRJA15         NaN         NaN   -1.334821    0.747619   \n",
            "A1GI0U000302ZRJA16   -0.277273   -2.346341    0.665179    0.747619   \n",
            "A1GI0U000303ZRJA17   -2.277273         NaN   -0.334821         NaN   \n",
            "\n",
            "                    Product_19  Product_20  \n",
            "A1GI0U000004ZRJA8     0.683258         NaN  \n",
            "A1GI0U000005ZRJA9          NaN    0.642512  \n",
            "A1GI0U000006ZRJA10    0.683258         NaN  \n",
            "A1GI0U000007ZRJA11         NaN    0.642512  \n",
            "A1GI0U000008ZRJA12    0.683258   -1.357488  \n",
            "...                        ...         ...  \n",
            "A1GI0U000299ZRJA13    0.683258    0.642512  \n",
            "A1GI0U000300ZRJA14    0.683258    0.642512  \n",
            "A1GI0U000301ZRJA15    0.683258         NaN  \n",
            "A1GI0U000302ZRJA16         NaN         NaN  \n",
            "A1GI0U000303ZRJA17   -2.316742         NaN  \n",
            "\n",
            "[300 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the covariance matrix\n",
        "covariance_matrix = rating_diff.cov()\n",
        "\n",
        "print(\"Covariance Matrix:\")\n",
        "print(covariance_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBLZ-ciBmgFr",
        "outputId": "94b93055-0c5a-4f68-cec4-16451eec4be9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covariance Matrix:\n",
            "            Product_1  Product_2  Product_3  Product_4  Product_5  Product_6  \\\n",
            "Product_1    1.142174   0.190191  -0.012665   0.317809   0.014984   0.006993   \n",
            "Product_2    0.190191   1.352142  -0.096865   0.069501   0.164368   0.024087   \n",
            "Product_3   -0.012665  -0.096865   1.392481   0.007196   0.026918   0.229947   \n",
            "Product_4    0.317809   0.069501   0.007196   1.460873  -0.071981  -0.046360   \n",
            "Product_5    0.014984   0.164368   0.026918  -0.071981   1.261657  -0.094232   \n",
            "Product_6    0.006993   0.024087   0.229947  -0.046360  -0.094232   1.080926   \n",
            "Product_7   -0.080940  -0.190528  -0.005651   0.056150   0.045666  -0.010022   \n",
            "Product_8    0.071886   0.093827  -0.025386   0.098543   0.018225  -0.029923   \n",
            "Product_9    0.184441   0.122713   0.044377   0.254294   0.069744   0.026023   \n",
            "Product_10   0.135608   0.010150   0.012107  -0.074422  -0.023060   0.266391   \n",
            "Product_11  -0.016040  -0.068110  -0.056945  -0.067654  -0.003163   0.026857   \n",
            "Product_12  -0.111227  -0.171817   0.076422  -0.007761   0.019768   0.027706   \n",
            "Product_13  -0.060386   0.062252   0.053602   0.040489  -0.053163  -0.105378   \n",
            "Product_14  -0.066444  -0.066717  -0.157737  -0.053147   0.050311  -0.005319   \n",
            "Product_15  -0.034691   0.071860   0.021262  -0.052601  -0.009288   0.001299   \n",
            "Product_16   0.068127   0.162685  -0.013209   0.008653  -0.162541   0.188736   \n",
            "Product_17   0.064799   0.038054   0.090860  -0.055229  -0.092296  -0.019226   \n",
            "Product_18   0.071800  -0.084770   0.108568  -0.031484  -0.005272  -0.017181   \n",
            "Product_19  -0.093094  -0.194805  -0.000087  -0.119400   0.073493  -0.188583   \n",
            "Product_20  -0.085098  -0.053411  -0.137847   0.000635   0.143504  -0.114422   \n",
            "\n",
            "            Product_7  Product_8  Product_9  Product_10  Product_11  \\\n",
            "Product_1   -0.080940   0.071886   0.184441    0.135608   -0.016040   \n",
            "Product_2   -0.190528   0.093827   0.122713    0.010150   -0.068110   \n",
            "Product_3   -0.005651  -0.025386   0.044377    0.012107   -0.056945   \n",
            "Product_4    0.056150   0.098543   0.254294   -0.074422   -0.067654   \n",
            "Product_5    0.045666   0.018225   0.069744   -0.023060   -0.003163   \n",
            "Product_6   -0.010022  -0.029923   0.026023    0.266391    0.026857   \n",
            "Product_7    1.295780  -0.003751   0.048949    0.078675    0.023314   \n",
            "Product_8   -0.003751   1.000153  -0.036889    0.027204    0.101412   \n",
            "Product_9    0.048949  -0.036889   1.293611   -0.058824    0.004416   \n",
            "Product_10   0.078675   0.027204  -0.058824    1.006175    0.060828   \n",
            "Product_11   0.023314   0.101412   0.004416    0.060828    1.079535   \n",
            "Product_12  -0.144399  -0.045312  -0.080394   -0.048247   -0.041667   \n",
            "Product_13  -0.059748  -0.105633   0.243741   -0.034217    0.008837   \n",
            "Product_14  -0.030007  -0.091228   0.065693   -0.158580    0.110658   \n",
            "Product_15  -0.012605  -0.032773   0.039735    0.082488    0.183043   \n",
            "Product_16  -0.258641   0.134932  -0.082407    0.088689    0.053220   \n",
            "Product_17  -0.068431   0.076386   0.017584    0.045294   -0.071087   \n",
            "Product_18  -0.060829  -0.129957  -0.204475    0.042925   -0.019433   \n",
            "Product_19  -0.034865   0.236290  -0.186868    0.012831    0.049226   \n",
            "Product_20  -0.013423  -0.044561  -0.018797    0.021695   -0.121299   \n",
            "\n",
            "            Product_12  Product_13  Product_14  Product_15  Product_16  \\\n",
            "Product_1    -0.111227   -0.060386   -0.066444   -0.034691    0.068127   \n",
            "Product_2    -0.171817    0.062252   -0.066717    0.071860    0.162685   \n",
            "Product_3     0.076422    0.053602   -0.157737    0.021262   -0.013209   \n",
            "Product_4    -0.007761    0.040489   -0.053147   -0.052601    0.008653   \n",
            "Product_5     0.019768   -0.053163    0.050311   -0.009288   -0.162541   \n",
            "Product_6     0.027706   -0.105378   -0.005319    0.001299    0.188736   \n",
            "Product_7    -0.144399   -0.059748   -0.030007   -0.012605   -0.258641   \n",
            "Product_8    -0.045312   -0.105633   -0.091228   -0.032773    0.134932   \n",
            "Product_9    -0.080394    0.243741    0.065693    0.039735   -0.082407   \n",
            "Product_10   -0.048247   -0.034217   -0.158580    0.082488    0.088689   \n",
            "Product_11   -0.041667    0.008837    0.110658    0.183043    0.053220   \n",
            "Product_12    1.073929    0.052564    0.021156    0.003681   -0.025236   \n",
            "Product_13    0.052564    1.045364   -0.029530   -0.069837   -0.195977   \n",
            "Product_14    0.021156   -0.029530    1.107388    0.000559    0.050019   \n",
            "Product_15    0.003681   -0.069837    0.000559    1.470714    0.011353   \n",
            "Product_16   -0.025236   -0.195977    0.050019    0.011353    1.276518   \n",
            "Product_17   -0.077595   -0.090603    0.135727   -0.007095   -0.003183   \n",
            "Product_18    0.079560   -0.038586   -0.014957    0.059788   -0.014801   \n",
            "Product_19    0.058574   -0.004141   -0.063758   -0.033491    0.089559   \n",
            "Product_20   -0.070912    0.029397    0.196226   -0.033996    0.004759   \n",
            "\n",
            "            Product_17  Product_18  Product_19  Product_20  \n",
            "Product_1     0.064799    0.071800   -0.093094   -0.085098  \n",
            "Product_2     0.038054   -0.084770   -0.194805   -0.053411  \n",
            "Product_3     0.090860    0.108568   -0.000087   -0.137847  \n",
            "Product_4    -0.055229   -0.031484   -0.119400    0.000635  \n",
            "Product_5    -0.092296   -0.005272    0.073493    0.143504  \n",
            "Product_6    -0.019226   -0.017181   -0.188583   -0.114422  \n",
            "Product_7    -0.068431   -0.060829   -0.034865   -0.013423  \n",
            "Product_8     0.076386   -0.129957    0.236290   -0.044561  \n",
            "Product_9     0.017584   -0.204475   -0.186868   -0.018797  \n",
            "Product_10    0.045294    0.042925    0.012831    0.021695  \n",
            "Product_11   -0.071087   -0.019433    0.049226   -0.121299  \n",
            "Product_12   -0.077595    0.079560    0.058574   -0.070912  \n",
            "Product_13   -0.090603   -0.038586   -0.004141    0.029397  \n",
            "Product_14    0.135727   -0.014957   -0.063758    0.196226  \n",
            "Product_15   -0.007095    0.059788   -0.033491   -0.033996  \n",
            "Product_16   -0.003183   -0.014801    0.089559    0.004759  \n",
            "Product_17    1.273042    0.005644    0.021455    0.030872  \n",
            "Product_18    0.005644    1.414468    0.006349   -0.082260  \n",
            "Product_19    0.021455    0.006349    1.290128   -0.214498  \n",
            "Product_20    0.030872   -0.082260   -0.214498    1.415271  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the covariance matrix\n",
        "covariance_matrix = rating_diff.cov()\n",
        "\n",
        "print(\"Covariance Matrix:\")\n",
        "print(covariance_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkX0u_MFmt_p",
        "outputId": "cf30943f-53b0-4c1c-89b4-6cc3dc245f74"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Covariance Matrix:\n",
            "            Product_1  Product_2  Product_3  Product_4  Product_5  Product_6  \\\n",
            "Product_1    1.142174   0.190191  -0.012665   0.317809   0.014984   0.006993   \n",
            "Product_2    0.190191   1.352142  -0.096865   0.069501   0.164368   0.024087   \n",
            "Product_3   -0.012665  -0.096865   1.392481   0.007196   0.026918   0.229947   \n",
            "Product_4    0.317809   0.069501   0.007196   1.460873  -0.071981  -0.046360   \n",
            "Product_5    0.014984   0.164368   0.026918  -0.071981   1.261657  -0.094232   \n",
            "Product_6    0.006993   0.024087   0.229947  -0.046360  -0.094232   1.080926   \n",
            "Product_7   -0.080940  -0.190528  -0.005651   0.056150   0.045666  -0.010022   \n",
            "Product_8    0.071886   0.093827  -0.025386   0.098543   0.018225  -0.029923   \n",
            "Product_9    0.184441   0.122713   0.044377   0.254294   0.069744   0.026023   \n",
            "Product_10   0.135608   0.010150   0.012107  -0.074422  -0.023060   0.266391   \n",
            "Product_11  -0.016040  -0.068110  -0.056945  -0.067654  -0.003163   0.026857   \n",
            "Product_12  -0.111227  -0.171817   0.076422  -0.007761   0.019768   0.027706   \n",
            "Product_13  -0.060386   0.062252   0.053602   0.040489  -0.053163  -0.105378   \n",
            "Product_14  -0.066444  -0.066717  -0.157737  -0.053147   0.050311  -0.005319   \n",
            "Product_15  -0.034691   0.071860   0.021262  -0.052601  -0.009288   0.001299   \n",
            "Product_16   0.068127   0.162685  -0.013209   0.008653  -0.162541   0.188736   \n",
            "Product_17   0.064799   0.038054   0.090860  -0.055229  -0.092296  -0.019226   \n",
            "Product_18   0.071800  -0.084770   0.108568  -0.031484  -0.005272  -0.017181   \n",
            "Product_19  -0.093094  -0.194805  -0.000087  -0.119400   0.073493  -0.188583   \n",
            "Product_20  -0.085098  -0.053411  -0.137847   0.000635   0.143504  -0.114422   \n",
            "\n",
            "            Product_7  Product_8  Product_9  Product_10  Product_11  \\\n",
            "Product_1   -0.080940   0.071886   0.184441    0.135608   -0.016040   \n",
            "Product_2   -0.190528   0.093827   0.122713    0.010150   -0.068110   \n",
            "Product_3   -0.005651  -0.025386   0.044377    0.012107   -0.056945   \n",
            "Product_4    0.056150   0.098543   0.254294   -0.074422   -0.067654   \n",
            "Product_5    0.045666   0.018225   0.069744   -0.023060   -0.003163   \n",
            "Product_6   -0.010022  -0.029923   0.026023    0.266391    0.026857   \n",
            "Product_7    1.295780  -0.003751   0.048949    0.078675    0.023314   \n",
            "Product_8   -0.003751   1.000153  -0.036889    0.027204    0.101412   \n",
            "Product_9    0.048949  -0.036889   1.293611   -0.058824    0.004416   \n",
            "Product_10   0.078675   0.027204  -0.058824    1.006175    0.060828   \n",
            "Product_11   0.023314   0.101412   0.004416    0.060828    1.079535   \n",
            "Product_12  -0.144399  -0.045312  -0.080394   -0.048247   -0.041667   \n",
            "Product_13  -0.059748  -0.105633   0.243741   -0.034217    0.008837   \n",
            "Product_14  -0.030007  -0.091228   0.065693   -0.158580    0.110658   \n",
            "Product_15  -0.012605  -0.032773   0.039735    0.082488    0.183043   \n",
            "Product_16  -0.258641   0.134932  -0.082407    0.088689    0.053220   \n",
            "Product_17  -0.068431   0.076386   0.017584    0.045294   -0.071087   \n",
            "Product_18  -0.060829  -0.129957  -0.204475    0.042925   -0.019433   \n",
            "Product_19  -0.034865   0.236290  -0.186868    0.012831    0.049226   \n",
            "Product_20  -0.013423  -0.044561  -0.018797    0.021695   -0.121299   \n",
            "\n",
            "            Product_12  Product_13  Product_14  Product_15  Product_16  \\\n",
            "Product_1    -0.111227   -0.060386   -0.066444   -0.034691    0.068127   \n",
            "Product_2    -0.171817    0.062252   -0.066717    0.071860    0.162685   \n",
            "Product_3     0.076422    0.053602   -0.157737    0.021262   -0.013209   \n",
            "Product_4    -0.007761    0.040489   -0.053147   -0.052601    0.008653   \n",
            "Product_5     0.019768   -0.053163    0.050311   -0.009288   -0.162541   \n",
            "Product_6     0.027706   -0.105378   -0.005319    0.001299    0.188736   \n",
            "Product_7    -0.144399   -0.059748   -0.030007   -0.012605   -0.258641   \n",
            "Product_8    -0.045312   -0.105633   -0.091228   -0.032773    0.134932   \n",
            "Product_9    -0.080394    0.243741    0.065693    0.039735   -0.082407   \n",
            "Product_10   -0.048247   -0.034217   -0.158580    0.082488    0.088689   \n",
            "Product_11   -0.041667    0.008837    0.110658    0.183043    0.053220   \n",
            "Product_12    1.073929    0.052564    0.021156    0.003681   -0.025236   \n",
            "Product_13    0.052564    1.045364   -0.029530   -0.069837   -0.195977   \n",
            "Product_14    0.021156   -0.029530    1.107388    0.000559    0.050019   \n",
            "Product_15    0.003681   -0.069837    0.000559    1.470714    0.011353   \n",
            "Product_16   -0.025236   -0.195977    0.050019    0.011353    1.276518   \n",
            "Product_17   -0.077595   -0.090603    0.135727   -0.007095   -0.003183   \n",
            "Product_18    0.079560   -0.038586   -0.014957    0.059788   -0.014801   \n",
            "Product_19    0.058574   -0.004141   -0.063758   -0.033491    0.089559   \n",
            "Product_20   -0.070912    0.029397    0.196226   -0.033996    0.004759   \n",
            "\n",
            "            Product_17  Product_18  Product_19  Product_20  \n",
            "Product_1     0.064799    0.071800   -0.093094   -0.085098  \n",
            "Product_2     0.038054   -0.084770   -0.194805   -0.053411  \n",
            "Product_3     0.090860    0.108568   -0.000087   -0.137847  \n",
            "Product_4    -0.055229   -0.031484   -0.119400    0.000635  \n",
            "Product_5    -0.092296   -0.005272    0.073493    0.143504  \n",
            "Product_6    -0.019226   -0.017181   -0.188583   -0.114422  \n",
            "Product_7    -0.068431   -0.060829   -0.034865   -0.013423  \n",
            "Product_8     0.076386   -0.129957    0.236290   -0.044561  \n",
            "Product_9     0.017584   -0.204475   -0.186868   -0.018797  \n",
            "Product_10    0.045294    0.042925    0.012831    0.021695  \n",
            "Product_11   -0.071087   -0.019433    0.049226   -0.121299  \n",
            "Product_12   -0.077595    0.079560    0.058574   -0.070912  \n",
            "Product_13   -0.090603   -0.038586   -0.004141    0.029397  \n",
            "Product_14    0.135727   -0.014957   -0.063758    0.196226  \n",
            "Product_15   -0.007095    0.059788   -0.033491   -0.033996  \n",
            "Product_16   -0.003183   -0.014801    0.089559    0.004759  \n",
            "Product_17    1.273042    0.005644    0.021455    0.030872  \n",
            "Product_18    0.005644    1.414468    0.006349   -0.082260  \n",
            "Product_19    0.021455    0.006349    1.290128   -0.214498  \n",
            "Product_20    0.030872   -0.082260   -0.214498    1.415271  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the top 5-peers and top 10-peers for each target item\n",
        "top_5_peers_I1 = covariance_matrix[I1].nlargest(6).index.drop(I1).tolist()\n",
        "top_10_peers_I1 = covariance_matrix[I1].nlargest(11).index.drop(I1).tolist()\n",
        "\n",
        "top_5_peers_I2 = covariance_matrix[I2].nlargest(6).index.drop(I2).tolist()\n",
        "top_10_peers_I2 = covariance_matrix[I2].nlargest(11).index.drop(I2).tolist()\n",
        "\n",
        "print(f\"Top 5 Peers for {I1}: {top_5_peers_I1}\")\n",
        "print(f\"Top 10 Peers for {I1}: {top_10_peers_I1}\")\n",
        "print(f\"Top 5 Peers for {I2}: {top_5_peers_I2}\")\n",
        "print(f\"Top 10 Peers for {I2}: {top_10_peers_I2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92jDvsFumyGo",
        "outputId": "a87cf7e2-53f4-4241-f44f-b0e548dcd1fb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Peers for Product_11: ['Product_15', 'Product_14', 'Product_8', 'Product_10', 'Product_16']\n",
            "Top 10 Peers for Product_11: ['Product_15', 'Product_14', 'Product_8', 'Product_10', 'Product_16', 'Product_19', 'Product_6', 'Product_7', 'Product_13', 'Product_9']\n",
            "Top 5 Peers for Product_8: ['Product_19', 'Product_16', 'Product_11', 'Product_4', 'Product_2']\n",
            "Top 10 Peers for Product_8: ['Product_19', 'Product_16', 'Product_11', 'Product_4', 'Product_2', 'Product_17', 'Product_1', 'Product_10', 'Product_5', 'Product_7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create reduced dimensional space for each user using top 5-peers\n",
        "reduced_space_top_5_I1 = df[top_5_peers_I1]\n",
        "reduced_space_top_5_I2 = df[top_5_peers_I2]\n",
        "\n",
        "print(\"Reduced Dimensional Space for Top 5-Peers (I1):\")\n",
        "print(reduced_space_top_5_I1.head())\n",
        "print(\"Reduced Dimensional Space for Top 5-Peers (I2):\")\n",
        "print(reduced_space_top_5_I2.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6L4mjjbm2U9",
        "outputId": "149b613e-7cad-4cdb-f44c-3f58a7456b8e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced Dimensional Space for Top 5-Peers (I1):\n",
            "                    Product_15  Product_14  Product_8  Product_10  Product_16\n",
            "A1GI0U000004ZRJA8          NaN         5.0   1.000000         5.0         NaN\n",
            "A1GI0U000005ZRJA9          3.0         NaN   3.000000         5.0         5.0\n",
            "A1GI0U000006ZRJA10         NaN         5.0   4.000000         2.0         5.0\n",
            "A1GI0U000007ZRJA11         5.0         NaN   4.000000         5.0         3.0\n",
            "A1GI0U000008ZRJA12         5.0         5.0   4.213198         NaN         5.0\n",
            "Reduced Dimensional Space for Top 5-Peers (I2):\n",
            "                    Product_19  Product_16  Product_11  Product_4  Product_2\n",
            "A1GI0U000004ZRJA8          5.0         NaN    5.000000        1.0        3.0\n",
            "A1GI0U000005ZRJA9          NaN         5.0    3.000000        5.0        NaN\n",
            "A1GI0U000006ZRJA10         5.0         5.0    4.209524        5.0        NaN\n",
            "A1GI0U000007ZRJA11         NaN         3.0    3.000000        3.0        5.0\n",
            "A1GI0U000008ZRJA12         5.0         5.0    5.000000        3.0        5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict missing ratings for I1 and I2 using top 5-peers\n",
        "predicted_rating_I1_top_5 = reduced_space_top_5_I1.mean(axis=1)\n",
        "predicted_rating_I2_top_5 = reduced_space_top_5_I2.mean(axis=1)\n",
        "\n",
        "print(\"Predicted Ratings for I1 using Top 5-Peers:\")\n",
        "print(predicted_rating_I1_top_5)\n",
        "print(\"Predicted Ratings for I2 using Top 5-Peers:\")\n",
        "print(predicted_rating_I2_top_5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GoQBqxQm5-1",
        "outputId": "f69d409a-fb88-4b3d-b03a-5b5c9d9e03e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Ratings for I1 using Top 5-Peers:\n",
            "A1GI0U000004ZRJA8     3.666667\n",
            "A1GI0U000005ZRJA9     4.000000\n",
            "A1GI0U000006ZRJA10    4.000000\n",
            "A1GI0U000007ZRJA11    4.250000\n",
            "A1GI0U000008ZRJA12    4.803299\n",
            "                        ...   \n",
            "A1GI0U000299ZRJA13    3.737733\n",
            "A1GI0U000300ZRJA14    4.750000\n",
            "A1GI0U000301ZRJA15    4.000000\n",
            "A1GI0U000302ZRJA16    3.400000\n",
            "A1GI0U000303ZRJA17    4.250000\n",
            "Length: 300, dtype: float64\n",
            "Predicted Ratings for I2 using Top 5-Peers:\n",
            "A1GI0U000004ZRJA8     3.500000\n",
            "A1GI0U000005ZRJA9     4.333333\n",
            "A1GI0U000006ZRJA10    4.802381\n",
            "A1GI0U000007ZRJA11    3.500000\n",
            "A1GI0U000008ZRJA12    4.600000\n",
            "                        ...   \n",
            "A1GI0U000299ZRJA13    4.736508\n",
            "A1GI0U000300ZRJA14    4.500000\n",
            "A1GI0U000301ZRJA15    5.000000\n",
            "A1GI0U000302ZRJA16    4.052381\n",
            "A1GI0U000303ZRJA17    4.052381\n",
            "Length: 300, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create reduced dimensional space for each user using top 10-peers\n",
        "reduced_space_top_10_I1 = df[top_10_peers_I1]\n",
        "reduced_space_top_10_I2 = df[top_10_peers_I2]\n",
        "\n",
        "print(\"Reduced Dimensional Space for Top 10-Peers (I1):\")\n",
        "print(reduced_space_top_10_I1.head())\n",
        "print(\"Reduced Dimensional Space for Top 10-Peers (I2):\")\n",
        "print(reduced_space_top_10_I2.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BIhkHaGm8Zz",
        "outputId": "cd1f0812-0eef-4837-9324-74761285febd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced Dimensional Space for Top 10-Peers (I1):\n",
            "                    Product_15  Product_14  Product_8  Product_10  Product_16  \\\n",
            "A1GI0U000004ZRJA8          NaN         5.0   1.000000         5.0         NaN   \n",
            "A1GI0U000005ZRJA9          3.0         NaN   3.000000         5.0         5.0   \n",
            "A1GI0U000006ZRJA10         NaN         5.0   4.000000         2.0         5.0   \n",
            "A1GI0U000007ZRJA11         5.0         NaN   4.000000         5.0         3.0   \n",
            "A1GI0U000008ZRJA12         5.0         5.0   4.213198         NaN         5.0   \n",
            "\n",
            "                    Product_19  Product_6  Product_7  Product_13  Product_9  \n",
            "A1GI0U000004ZRJA8          5.0        5.0        5.0         5.0        4.0  \n",
            "A1GI0U000005ZRJA9          NaN        5.0        NaN         NaN        5.0  \n",
            "A1GI0U000006ZRJA10         5.0        4.0        3.0         5.0        NaN  \n",
            "A1GI0U000007ZRJA11         NaN        4.0        5.0         5.0        NaN  \n",
            "A1GI0U000008ZRJA12         5.0        NaN        3.0         4.0        5.0  \n",
            "Reduced Dimensional Space for Top 10-Peers (I2):\n",
            "                    Product_19  Product_16  Product_11  Product_4  Product_2  \\\n",
            "A1GI0U000004ZRJA8          5.0         NaN    5.000000        1.0        3.0   \n",
            "A1GI0U000005ZRJA9          NaN         5.0    3.000000        5.0        NaN   \n",
            "A1GI0U000006ZRJA10         5.0         5.0    4.209524        5.0        NaN   \n",
            "A1GI0U000007ZRJA11         NaN         3.0    3.000000        3.0        5.0   \n",
            "A1GI0U000008ZRJA12         5.0         5.0    5.000000        3.0        5.0   \n",
            "\n",
            "                    Product_17  Product_1  Product_10  Product_5  Product_7  \n",
            "A1GI0U000004ZRJA8          4.0        2.0         5.0        5.0        5.0  \n",
            "A1GI0U000005ZRJA9          NaN        5.0         5.0        NaN        NaN  \n",
            "A1GI0U000006ZRJA10         5.0        NaN         2.0        NaN        3.0  \n",
            "A1GI0U000007ZRJA11         5.0        NaN         5.0        5.0        5.0  \n",
            "A1GI0U000008ZRJA12         5.0        NaN         NaN        NaN        3.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict missing ratings for I1 and I2 using top 10-peers\n",
        "predicted_rating_I1_top_10 = reduced_space_top_10_I1.mean(axis=1)\n",
        "predicted_rating_I2_top_10 = reduced_space_top_10_I2.mean(axis=1)\n",
        "\n",
        "print(\"Predicted Ratings for I1 using Top 10-Peers:\")\n",
        "print(predicted_rating_I1_top_10)\n",
        "print(\"Predicted Ratings for I2 using Top 10-Peers:\")\n",
        "print(predicted_rating_I2_top_10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXFub3uTm-yJ",
        "outputId": "f3ce6bcd-2ba0-43fd-9c43-79b829254bc9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Ratings for I1 using Top 10-Peers:\n",
            "A1GI0U000004ZRJA8     4.375000\n",
            "A1GI0U000005ZRJA9     4.333333\n",
            "A1GI0U000006ZRJA10    4.125000\n",
            "A1GI0U000007ZRJA11    4.428571\n",
            "A1GI0U000008ZRJA12    4.526650\n",
            "                        ...   \n",
            "A1GI0U000299ZRJA13    4.459028\n",
            "A1GI0U000300ZRJA14    4.625000\n",
            "A1GI0U000301ZRJA15    4.625000\n",
            "A1GI0U000302ZRJA16    3.857143\n",
            "A1GI0U000303ZRJA17    4.000000\n",
            "Length: 300, dtype: float64\n",
            "Predicted Ratings for I2 using Top 10-Peers:\n",
            "A1GI0U000004ZRJA8     3.888889\n",
            "A1GI0U000005ZRJA9     4.600000\n",
            "A1GI0U000006ZRJA10    4.172789\n",
            "A1GI0U000007ZRJA11    4.250000\n",
            "A1GI0U000008ZRJA12    4.428571\n",
            "                        ...   \n",
            "A1GI0U000299ZRJA13    4.701587\n",
            "A1GI0U000300ZRJA14    4.625000\n",
            "A1GI0U000301ZRJA15    4.500000\n",
            "A1GI0U000302ZRJA16    4.401190\n",
            "A1GI0U000303ZRJA17    4.201587\n",
            "Length: 300, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the predictions using Top 5-Peers and Top 10-Peers\n",
        "comparison_I1 = pd.DataFrame({\n",
        "    \"Top 5-Peers\": predicted_rating_I1_top_5,\n",
        "    \"Top 10-Peers\": predicted_rating_I1_top_10\n",
        "})\n",
        "\n",
        "comparison_I2 = pd.DataFrame({\n",
        "    \"Top 5-Peers\": predicted_rating_I2_top_5,\n",
        "    \"Top 10-Peers\": predicted_rating_I2_top_10\n",
        "})\n",
        "\n",
        "print(\"Comparison for I1:\")\n",
        "print(comparison_I1)\n",
        "\n",
        "print(\"Comparison for I2:\")\n",
        "print(comparison_I2)\n",
        "\n",
        "# Comment on the comparison\n",
        "print(\"The comparison indicates how including more peers affects the rating predictions. Analyze the results for differences.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKbu_cTenBOr",
        "outputId": "d527676f-805c-4401-891d-eddab647a431"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison for I1:\n",
            "                    Top 5-Peers  Top 10-Peers\n",
            "A1GI0U000004ZRJA8      3.666667      4.375000\n",
            "A1GI0U000005ZRJA9      4.000000      4.333333\n",
            "A1GI0U000006ZRJA10     4.000000      4.125000\n",
            "A1GI0U000007ZRJA11     4.250000      4.428571\n",
            "A1GI0U000008ZRJA12     4.803299      4.526650\n",
            "...                         ...           ...\n",
            "A1GI0U000299ZRJA13     3.737733      4.459028\n",
            "A1GI0U000300ZRJA14     4.750000      4.625000\n",
            "A1GI0U000301ZRJA15     4.000000      4.625000\n",
            "A1GI0U000302ZRJA16     3.400000      3.857143\n",
            "A1GI0U000303ZRJA17     4.250000      4.000000\n",
            "\n",
            "[300 rows x 2 columns]\n",
            "Comparison for I2:\n",
            "                    Top 5-Peers  Top 10-Peers\n",
            "A1GI0U000004ZRJA8      3.500000      3.888889\n",
            "A1GI0U000005ZRJA9      4.333333      4.600000\n",
            "A1GI0U000006ZRJA10     4.802381      4.172789\n",
            "A1GI0U000007ZRJA11     3.500000      4.250000\n",
            "A1GI0U000008ZRJA12     4.600000      4.428571\n",
            "...                         ...           ...\n",
            "A1GI0U000299ZRJA13     4.736508      4.701587\n",
            "A1GI0U000300ZRJA14     4.500000      4.625000\n",
            "A1GI0U000301ZRJA15     5.000000      4.500000\n",
            "A1GI0U000302ZRJA16     4.052381      4.401190\n",
            "A1GI0U000303ZRJA17     4.052381      4.201587\n",
            "\n",
            "[300 rows x 2 columns]\n",
            "The comparison indicates how including more peers affects the rating predictions. Analyze the results for differences.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the covariance matrix using Maximum Likelihood Estimation\n",
        "def compute_mle_covariance(df):\n",
        "    n_items = df.shape[1]\n",
        "    mle_covariance = pd.DataFrame(0, index=df.columns, columns=df.columns)\n",
        "\n",
        "    for i in df.columns:\n",
        "        for j in df.columns:\n",
        "            # Get common ratings for the pair of items\n",
        "            common_ratings = df[[i, j]].dropna()\n",
        "            if len(common_ratings) > 0:\n",
        "                mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
        "            else:\n",
        "                mle_covariance.loc[i, j] = 0\n",
        "\n",
        "    return mle_covariance\n",
        "\n",
        "mle_covariance_matrix = compute_mle_covariance(df)\n",
        "\n",
        "print(\"MLE Covariance Matrix:\")\n",
        "print(mle_covariance_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn2ooA8DqoVb",
        "outputId": "af41dae3-d6c0-476c-897c-df43cb2feee6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.14362529089358106' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.01054372009315537' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.26026910843063034' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.014439381496435947' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.006334218856467266' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.0592087604974073' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.06623488485663062' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.1471988538864695' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.12384057711488007' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.014347427603371408' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.10738056297470071' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.05328557882204739' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.056148452280419314' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.02852584566205214' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.062617962548146' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.049521545911475305' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.051241028434381934' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.07689591593865494' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.07021647017869032' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n",
            "<ipython-input-21-62cd9b578bc4>:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.14362529089358106' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  mle_covariance.loc[i, j] = common_ratings.corr().iloc[0, 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLE Covariance Matrix:\n",
            "            Product_1  Product_2  Product_3  Product_4  Product_5  Product_6  \\\n",
            "Product_1    1.000000   0.143625  -0.010544   0.260269   0.014439   0.006334   \n",
            "Product_2    0.143625   1.000000  -0.067247   0.045489   0.127748   0.017740   \n",
            "Product_3   -0.010544  -0.067247   1.000000   0.005062   0.022762   0.166745   \n",
            "Product_4    0.260269   0.045489   0.005062   1.000000  -0.053583  -0.036713   \n",
            "Product_5    0.014439   0.127748   0.022762  -0.053583   1.000000  -0.082209   \n",
            "Product_6    0.006334   0.017740   0.166745  -0.036713  -0.082209   1.000000   \n",
            "Product_7   -0.059209  -0.137659  -0.004235   0.040003   0.035941  -0.008494   \n",
            "Product_8    0.066235   0.081582  -0.021764   0.080314   0.015890  -0.026948   \n",
            "Product_9    0.147199   0.083421   0.040776   0.189714   0.055879   0.026515   \n",
            "Product_10   0.123841   0.009270   0.011112  -0.060749  -0.021608   0.244580   \n",
            "Product_11  -0.014347  -0.057251  -0.046061  -0.054101  -0.002577   0.026397   \n",
            "Product_12  -0.107381  -0.139216   0.060898  -0.005783   0.017708   0.025760   \n",
            "Product_13  -0.053286   0.055667   0.049471   0.033537  -0.046091  -0.094389   \n",
            "Product_14  -0.056148  -0.058065  -0.119037  -0.042614   0.045854  -0.004704   \n",
            "Product_15  -0.028526   0.049822   0.014833  -0.035431  -0.007177   0.001044   \n",
            "Product_16   0.062618   0.132752  -0.010403   0.006358  -0.125556   0.151884   \n",
            "Product_17   0.049522   0.028033   0.072748  -0.040242  -0.072372  -0.017126   \n",
            "Product_18   0.051241  -0.065988   0.072597  -0.021269  -0.004024  -0.012947   \n",
            "Product_19  -0.076896  -0.135854  -0.000066  -0.089970   0.058438  -0.148247   \n",
            "Product_20  -0.070216  -0.037645  -0.105211   0.000434   0.094970  -0.088973   \n",
            "\n",
            "            Product_7  Product_8  Product_9  Product_10  Product_11  \\\n",
            "Product_1   -0.059209   0.066235   0.147199    0.123841   -0.014347   \n",
            "Product_2   -0.137659   0.081582   0.083421    0.009270   -0.057251   \n",
            "Product_3   -0.004235  -0.021764   0.040776    0.011112   -0.046061   \n",
            "Product_4    0.040003   0.080314   0.189714   -0.060749   -0.054101   \n",
            "Product_5    0.035941   0.015890   0.055879   -0.021608   -0.002577   \n",
            "Product_6   -0.008494  -0.026948   0.026515    0.244580    0.026397   \n",
            "Product_7    1.000000  -0.003062   0.040037    0.069289    0.018690   \n",
            "Product_8   -0.003062   1.000000  -0.031121    0.026173    0.097598   \n",
            "Product_9    0.040037  -0.031121   1.000000   -0.049105    0.003470   \n",
            "Product_10   0.069289   0.026173  -0.049105    1.000000    0.059746   \n",
            "Product_11   0.018690   0.097598   0.003470    0.059746    1.000000   \n",
            "Product_12  -0.121633  -0.041898  -0.064359   -0.049467   -0.038105   \n",
            "Product_13  -0.050571  -0.100345   0.197616   -0.034726    0.008489   \n",
            "Product_14  -0.025101  -0.081851   0.059065   -0.136734    0.102100   \n",
            "Product_15  -0.009274  -0.027753   0.025823    0.067934    0.144528   \n",
            "Product_16  -0.190248   0.118932  -0.069140    0.075730    0.044913   \n",
            "Product_17  -0.053400   0.062566   0.013248    0.039380   -0.062067   \n",
            "Product_18  -0.040599  -0.112381  -0.139551    0.032442   -0.015756   \n",
            "Product_19  -0.026340   0.203887  -0.141973    0.011092    0.043056   \n",
            "Product_20  -0.011772  -0.038326  -0.014375    0.017353   -0.094197   \n",
            "\n",
            "            Product_12  Product_13  Product_14  Product_15  Product_16  \\\n",
            "Product_1    -0.107381   -0.053286   -0.056148   -0.028526    0.062618   \n",
            "Product_2    -0.139216    0.055667   -0.058065    0.049822    0.132752   \n",
            "Product_3     0.060898    0.049471   -0.119037    0.014833   -0.010403   \n",
            "Product_4    -0.005783    0.033537   -0.042614   -0.035431    0.006358   \n",
            "Product_5     0.017708   -0.046091    0.045854   -0.007177   -0.125556   \n",
            "Product_6     0.025760   -0.094389   -0.004704    0.001044    0.151884   \n",
            "Product_7    -0.121633   -0.050571   -0.025101   -0.009274   -0.190248   \n",
            "Product_8    -0.041898   -0.100345   -0.081851   -0.027753    0.118932   \n",
            "Product_9    -0.064359    0.197616    0.059065    0.025823   -0.069140   \n",
            "Product_10   -0.049467   -0.034726   -0.136734    0.067934    0.075730   \n",
            "Product_11   -0.038105    0.008489    0.102100    0.144528    0.044913   \n",
            "Product_12    1.000000    0.050513    0.021334    0.003094   -0.020282   \n",
            "Product_13    0.050513    1.000000   -0.026651   -0.056892   -0.165007   \n",
            "Product_14    0.021334   -0.026651    1.000000    0.000420    0.041283   \n",
            "Product_15    0.003094   -0.056892    0.000420    1.000000    0.008231   \n",
            "Product_16   -0.020282   -0.165007    0.041283    0.008231    1.000000   \n",
            "Product_17   -0.064753   -0.078759    0.108033   -0.005134   -0.002350   \n",
            "Product_18    0.071573   -0.032814   -0.012405    0.039643   -0.010360   \n",
            "Product_19    0.046237   -0.003337   -0.059498   -0.023811    0.067983   \n",
            "Product_20   -0.054906    0.025226    0.142272   -0.023512    0.003450   \n",
            "\n",
            "            Product_17  Product_18  Product_19  Product_20  \n",
            "Product_1     0.049522    0.051241   -0.076896   -0.070216  \n",
            "Product_2     0.028033   -0.065988   -0.135854   -0.037645  \n",
            "Product_3     0.072748    0.072597   -0.000066   -0.105211  \n",
            "Product_4    -0.040242   -0.021269   -0.089970    0.000434  \n",
            "Product_5    -0.072372   -0.004024    0.058438    0.094970  \n",
            "Product_6    -0.017126   -0.012947   -0.148247   -0.088973  \n",
            "Product_7    -0.053400   -0.040599   -0.026340   -0.011772  \n",
            "Product_8     0.062566   -0.112381    0.203887   -0.038326  \n",
            "Product_9     0.013248   -0.139551   -0.141973   -0.014375  \n",
            "Product_10    0.039380    0.032442    0.011092    0.017353  \n",
            "Product_11   -0.062067   -0.015756    0.043056   -0.094197  \n",
            "Product_12   -0.064753    0.071573    0.046237   -0.054906  \n",
            "Product_13   -0.078759   -0.032814   -0.003337    0.025226  \n",
            "Product_14    0.108033   -0.012405   -0.059498    0.142272  \n",
            "Product_15   -0.005134    0.039643   -0.023811   -0.023512  \n",
            "Product_16   -0.002350   -0.010360    0.067983    0.003450  \n",
            "Product_17    1.000000    0.004306    0.016766    0.022369  \n",
            "Product_18    0.004306    1.000000    0.005172   -0.053916  \n",
            "Product_19    0.016766    0.005172    1.000000   -0.154560  \n",
            "Product_20    0.022369   -0.053916   -0.154560    1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine top 5 and top 10 peers for I1 and I2\n",
        "top_5_peers_I1_mle = mle_covariance_matrix[I1].nlargest(6).index.drop(I1).tolist()\n",
        "top_10_peers_I1_mle = mle_covariance_matrix[I1].nlargest(11).index.drop(I1).tolist()\n",
        "\n",
        "top_5_peers_I2_mle = mle_covariance_matrix[I2].nlargest(6).index.drop(I2).tolist()\n",
        "top_10_peers_I2_mle = mle_covariance_matrix[I2].nlargest(11).index.drop(I2).tolist()\n",
        "\n",
        "print(f\"Top 5 Peers for {I1} (MLE): {top_5_peers_I1_mle}\")\n",
        "print(f\"Top 10 Peers for {I1} (MLE): {top_10_peers_I1_mle}\")\n",
        "print(f\"Top 5 Peers for {I2} (MLE): {top_5_peers_I2_mle}\")\n",
        "print(f\"Top 10 Peers for {I2} (MLE): {top_10_peers_I2_mle}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSSoTaDCqums",
        "outputId": "bab1ca15-6091-4e65-d1e2-70be1f9a2a98"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Peers for Product_11 (MLE): ['Product_15', 'Product_14', 'Product_8', 'Product_10', 'Product_16']\n",
            "Top 10 Peers for Product_11 (MLE): ['Product_15', 'Product_14', 'Product_8', 'Product_10', 'Product_16', 'Product_19', 'Product_6', 'Product_7', 'Product_13', 'Product_9']\n",
            "Top 5 Peers for Product_8 (MLE): ['Product_19', 'Product_16', 'Product_11', 'Product_2', 'Product_4']\n",
            "Top 10 Peers for Product_8 (MLE): ['Product_19', 'Product_16', 'Product_11', 'Product_2', 'Product_4', 'Product_1', 'Product_17', 'Product_10', 'Product_5', 'Product_7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create reduced dimensional space for each user using top 5 peers\n",
        "reduced_space_top_5_I1_mle = df[top_5_peers_I1_mle]\n",
        "reduced_space_top_5_I2_mle = df[top_5_peers_I2_mle]\n",
        "\n",
        "print(\"Reduced Dimensional Space for Top 5-Peers (I1):\")\n",
        "print(reduced_space_top_5_I1_mle.head())\n",
        "\n",
        "print(\"Reduced Dimensional Space for Top 5-Peers (I2):\")\n",
        "print(reduced_space_top_5_I2_mle.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMvMF7r-qwz6",
        "outputId": "2198c0da-58de-4b6f-e401-9ad5b029406a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced Dimensional Space for Top 5-Peers (I1):\n",
            "                    Product_15  Product_14  Product_8  Product_10  Product_16\n",
            "A1GI0U000004ZRJA8          NaN         5.0   1.000000         5.0         NaN\n",
            "A1GI0U000005ZRJA9          3.0         NaN   3.000000         5.0         5.0\n",
            "A1GI0U000006ZRJA10         NaN         5.0   4.000000         2.0         5.0\n",
            "A1GI0U000007ZRJA11         5.0         NaN   4.000000         5.0         3.0\n",
            "A1GI0U000008ZRJA12         5.0         5.0   4.213198         NaN         5.0\n",
            "Reduced Dimensional Space for Top 5-Peers (I2):\n",
            "                    Product_19  Product_16  Product_11  Product_2  Product_4\n",
            "A1GI0U000004ZRJA8          5.0         NaN    5.000000        3.0        1.0\n",
            "A1GI0U000005ZRJA9          NaN         5.0    3.000000        NaN        5.0\n",
            "A1GI0U000006ZRJA10         5.0         5.0    4.209524        NaN        5.0\n",
            "A1GI0U000007ZRJA11         NaN         3.0    3.000000        5.0        3.0\n",
            "A1GI0U000008ZRJA12         5.0         5.0    5.000000        5.0        3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict missing ratings for I1 and I2 using top 5 peers\n",
        "predicted_rating_I1_top_5_mle = reduced_space_top_5_I1_mle.mean(axis=1)\n",
        "predicted_rating_I2_top_5_mle = reduced_space_top_5_I2_mle.mean(axis=1)\n",
        "\n",
        "print(\"Predicted Ratings for I1 using Top 5-Peers (MLE):\")\n",
        "print(predicted_rating_I1_top_5_mle)\n",
        "\n",
        "print(\"Predicted Ratings for I2 using Top 5-Peers (MLE):\")\n",
        "print(predicted_rating_I2_top_5_mle)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASFUT3tFq1AV",
        "outputId": "b42ae0e2-736e-4f62-b700-f83c517dfbf2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Ratings for I1 using Top 5-Peers (MLE):\n",
            "A1GI0U000004ZRJA8     3.666667\n",
            "A1GI0U000005ZRJA9     4.000000\n",
            "A1GI0U000006ZRJA10    4.000000\n",
            "A1GI0U000007ZRJA11    4.250000\n",
            "A1GI0U000008ZRJA12    4.803299\n",
            "                        ...   \n",
            "A1GI0U000299ZRJA13    3.737733\n",
            "A1GI0U000300ZRJA14    4.750000\n",
            "A1GI0U000301ZRJA15    4.000000\n",
            "A1GI0U000302ZRJA16    3.400000\n",
            "A1GI0U000303ZRJA17    4.250000\n",
            "Length: 300, dtype: float64\n",
            "Predicted Ratings for I2 using Top 5-Peers (MLE):\n",
            "A1GI0U000004ZRJA8     3.500000\n",
            "A1GI0U000005ZRJA9     4.333333\n",
            "A1GI0U000006ZRJA10    4.802381\n",
            "A1GI0U000007ZRJA11    3.500000\n",
            "A1GI0U000008ZRJA12    4.600000\n",
            "                        ...   \n",
            "A1GI0U000299ZRJA13    4.736508\n",
            "A1GI0U000300ZRJA14    4.500000\n",
            "A1GI0U000301ZRJA15    5.000000\n",
            "A1GI0U000302ZRJA16    4.052381\n",
            "A1GI0U000303ZRJA17    4.052381\n",
            "Length: 300, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create reduced dimensional space for each user using top 10 peers\n",
        "reduced_space_top_10_I1_mle = df[top_10_peers_I1_mle]\n",
        "reduced_space_top_10_I2_mle = df[top_10_peers_I2_mle]\n",
        "\n",
        "print(\"Reduced Dimensional Space for Top 10-Peers (I1):\")\n",
        "print(reduced_space_top_10_I1_mle.head())\n",
        "\n",
        "print(\"Reduced Dimensional Space for Top 10-Peers (I2):\")\n",
        "print(reduced_space_top_10_I2_mle.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wbOe1ohq2YH",
        "outputId": "e6fc998f-6bd7-4d66-d7d0-f2482cbdbbed"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced Dimensional Space for Top 10-Peers (I1):\n",
            "                    Product_15  Product_14  Product_8  Product_10  Product_16  \\\n",
            "A1GI0U000004ZRJA8          NaN         5.0   1.000000         5.0         NaN   \n",
            "A1GI0U000005ZRJA9          3.0         NaN   3.000000         5.0         5.0   \n",
            "A1GI0U000006ZRJA10         NaN         5.0   4.000000         2.0         5.0   \n",
            "A1GI0U000007ZRJA11         5.0         NaN   4.000000         5.0         3.0   \n",
            "A1GI0U000008ZRJA12         5.0         5.0   4.213198         NaN         5.0   \n",
            "\n",
            "                    Product_19  Product_6  Product_7  Product_13  Product_9  \n",
            "A1GI0U000004ZRJA8          5.0        5.0        5.0         5.0        4.0  \n",
            "A1GI0U000005ZRJA9          NaN        5.0        NaN         NaN        5.0  \n",
            "A1GI0U000006ZRJA10         5.0        4.0        3.0         5.0        NaN  \n",
            "A1GI0U000007ZRJA11         NaN        4.0        5.0         5.0        NaN  \n",
            "A1GI0U000008ZRJA12         5.0        NaN        3.0         4.0        5.0  \n",
            "Reduced Dimensional Space for Top 10-Peers (I2):\n",
            "                    Product_19  Product_16  Product_11  Product_2  Product_4  \\\n",
            "A1GI0U000004ZRJA8          5.0         NaN    5.000000        3.0        1.0   \n",
            "A1GI0U000005ZRJA9          NaN         5.0    3.000000        NaN        5.0   \n",
            "A1GI0U000006ZRJA10         5.0         5.0    4.209524        NaN        5.0   \n",
            "A1GI0U000007ZRJA11         NaN         3.0    3.000000        5.0        3.0   \n",
            "A1GI0U000008ZRJA12         5.0         5.0    5.000000        5.0        3.0   \n",
            "\n",
            "                    Product_1  Product_17  Product_10  Product_5  Product_7  \n",
            "A1GI0U000004ZRJA8         2.0         4.0         5.0        5.0        5.0  \n",
            "A1GI0U000005ZRJA9         5.0         NaN         5.0        NaN        NaN  \n",
            "A1GI0U000006ZRJA10        NaN         5.0         2.0        NaN        3.0  \n",
            "A1GI0U000007ZRJA11        NaN         5.0         5.0        5.0        5.0  \n",
            "A1GI0U000008ZRJA12        NaN         5.0         NaN        NaN        3.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict missing ratings for I1 and I2 using top 10 peers\n",
        "predicted_rating_I1_top_10_mle = reduced_space_top_10_I1_mle.mean(axis=1)\n",
        "predicted_rating_I2_top_10_mle = reduced_space_top_10_I2_mle.mean(axis=1)\n",
        "\n",
        "print(\"Predicted Ratings for I1 using Top 10-Peers (MLE):\")\n",
        "print(predicted_rating_I1_top_10_mle)\n",
        "\n",
        "print(\"Predicted Ratings for I2 using Top 10-Peers (MLE):\")\n",
        "print(predicted_rating_I2_top_10_mle)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZioIPoSq6XU",
        "outputId": "082e135d-029b-4ded-d718-004d17cbadc9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Ratings for I1 using Top 10-Peers (MLE):\n",
            "A1GI0U000004ZRJA8     4.375000\n",
            "A1GI0U000005ZRJA9     4.333333\n",
            "A1GI0U000006ZRJA10    4.125000\n",
            "A1GI0U000007ZRJA11    4.428571\n",
            "A1GI0U000008ZRJA12    4.526650\n",
            "                        ...   \n",
            "A1GI0U000299ZRJA13    4.459028\n",
            "A1GI0U000300ZRJA14    4.625000\n",
            "A1GI0U000301ZRJA15    4.625000\n",
            "A1GI0U000302ZRJA16    3.857143\n",
            "A1GI0U000303ZRJA17    4.000000\n",
            "Length: 300, dtype: float64\n",
            "Predicted Ratings for I2 using Top 10-Peers (MLE):\n",
            "A1GI0U000004ZRJA8     3.888889\n",
            "A1GI0U000005ZRJA9     4.600000\n",
            "A1GI0U000006ZRJA10    4.172789\n",
            "A1GI0U000007ZRJA11    4.250000\n",
            "A1GI0U000008ZRJA12    4.428571\n",
            "                        ...   \n",
            "A1GI0U000299ZRJA13    4.701587\n",
            "A1GI0U000300ZRJA14    4.625000\n",
            "A1GI0U000301ZRJA15    4.500000\n",
            "A1GI0U000302ZRJA16    4.401190\n",
            "A1GI0U000303ZRJA17    4.201587\n",
            "Length: 300, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare predictions with top 5 peers and top 10 peers for MLE\n",
        "comparison_I1_mle = pd.DataFrame({\n",
        "    \"Top 5-Peers (MLE)\": predicted_rating_I1_top_5_mle,\n",
        "    \"Top 10-Peers (MLE)\": predicted_rating_I1_top_10_mle\n",
        "})\n",
        "\n",
        "comparison_I2_mle = pd.DataFrame({\n",
        "    \"Top 5-Peers (MLE)\": predicted_rating_I2_top_5_mle,\n",
        "    \"Top 10-Peers (MLE)\": predicted_rating_I2_top_10_mle\n",
        "})\n",
        "\n",
        "print(\"Comparison for I1 (MLE):\")\n",
        "print(comparison_I1_mle)\n",
        "\n",
        "print(\"Comparison for I2 (MLE):\")\n",
        "print(comparison_I2_mle)\n",
        "\n",
        "# Comment on comparisons\n",
        "print(\"The comparison shows differences in predictions using Top 5 and Top 10 peers.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DCCJrfsq8vJ",
        "outputId": "a1265dc7-7a56-4e04-8712-29bf5e69ba1e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison for I1 (MLE):\n",
            "                    Top 5-Peers (MLE)  Top 10-Peers (MLE)\n",
            "A1GI0U000004ZRJA8            3.666667            4.375000\n",
            "A1GI0U000005ZRJA9            4.000000            4.333333\n",
            "A1GI0U000006ZRJA10           4.000000            4.125000\n",
            "A1GI0U000007ZRJA11           4.250000            4.428571\n",
            "A1GI0U000008ZRJA12           4.803299            4.526650\n",
            "...                               ...                 ...\n",
            "A1GI0U000299ZRJA13           3.737733            4.459028\n",
            "A1GI0U000300ZRJA14           4.750000            4.625000\n",
            "A1GI0U000301ZRJA15           4.000000            4.625000\n",
            "A1GI0U000302ZRJA16           3.400000            3.857143\n",
            "A1GI0U000303ZRJA17           4.250000            4.000000\n",
            "\n",
            "[300 rows x 2 columns]\n",
            "Comparison for I2 (MLE):\n",
            "                    Top 5-Peers (MLE)  Top 10-Peers (MLE)\n",
            "A1GI0U000004ZRJA8            3.500000            3.888889\n",
            "A1GI0U000005ZRJA9            4.333333            4.600000\n",
            "A1GI0U000006ZRJA10           4.802381            4.172789\n",
            "A1GI0U000007ZRJA11           3.500000            4.250000\n",
            "A1GI0U000008ZRJA12           4.600000            4.428571\n",
            "...                               ...                 ...\n",
            "A1GI0U000299ZRJA13           4.736508            4.701587\n",
            "A1GI0U000300ZRJA14           4.500000            4.625000\n",
            "A1GI0U000301ZRJA15           5.000000            4.500000\n",
            "A1GI0U000302ZRJA16           4.052381            4.401190\n",
            "A1GI0U000303ZRJA17           4.052381            4.201587\n",
            "\n",
            "[300 rows x 2 columns]\n",
            "The comparison shows differences in predictions using Top 5 and Top 10 peers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average rating for each item\n",
        "average_ratings = df.mean()\n",
        "\n",
        "print(\"Average Ratings for Each Item:\")\n",
        "print(average_ratings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue1d-mlTq-yO",
        "outputId": "687e9b5c-d636-4866-b8c0-47b17b5216b0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Ratings for Each Item:\n",
            "Product_1     4.487685\n",
            "Product_2     4.367925\n",
            "Product_3     4.371429\n",
            "Product_4     4.273543\n",
            "Product_5     4.407583\n",
            "Product_6     4.433962\n",
            "Product_7     4.314815\n",
            "Product_8     4.213198\n",
            "Product_9     4.455882\n",
            "Product_10    4.477876\n",
            "Product_11    4.209524\n",
            "Product_12    4.458515\n",
            "Product_13    4.412844\n",
            "Product_14    4.451456\n",
            "Product_15    4.277273\n",
            "Product_16    4.346341\n",
            "Product_17    4.334821\n",
            "Product_18    4.252381\n",
            "Product_19    4.316742\n",
            "Product_20    4.357488\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with the mean rating of each item\n",
        "df_filled = df.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
        "\n",
        "print(\"Data After Mean-Filling:\")\n",
        "print(df_filled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wFat-EYtVcl",
        "outputId": "a1ff137a-e6e5-4c2d-862a-2f96bac20efb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data After Mean-Filling:\n",
            "                    Product_1  Product_2  Product_3  Product_4  Product_5  \\\n",
            "A1GI0U000004ZRJA8    2.000000   3.000000   4.371429   1.000000   5.000000   \n",
            "A1GI0U000005ZRJA9    5.000000   4.367925   4.371429   5.000000   4.407583   \n",
            "A1GI0U000006ZRJA10   4.487685   4.367925   4.371429   5.000000   4.407583   \n",
            "A1GI0U000007ZRJA11   4.487685   5.000000   3.000000   3.000000   5.000000   \n",
            "A1GI0U000008ZRJA12   4.487685   5.000000   5.000000   3.000000   4.407583   \n",
            "...                       ...        ...        ...        ...        ...   \n",
            "A1GI0U000299ZRJA13   4.000000   4.367925   5.000000   5.000000   4.407583   \n",
            "A1GI0U000300ZRJA14   4.487685   5.000000   4.371429   4.273543   5.000000   \n",
            "A1GI0U000301ZRJA15   4.487685   4.367925   3.000000   4.273543   5.000000   \n",
            "A1GI0U000302ZRJA16   5.000000   5.000000   5.000000   5.000000   4.407583   \n",
            "A1GI0U000303ZRJA17   4.487685   5.000000   1.000000   5.000000   4.407583   \n",
            "\n",
            "                    Product_6  Product_7  Product_8  Product_9  Product_10  \\\n",
            "A1GI0U000004ZRJA8    5.000000   5.000000   1.000000   4.000000    5.000000   \n",
            "A1GI0U000005ZRJA9    5.000000   4.314815   3.000000   5.000000    5.000000   \n",
            "A1GI0U000006ZRJA10   4.000000   3.000000   4.000000   4.455882    2.000000   \n",
            "A1GI0U000007ZRJA11   4.000000   5.000000   4.000000   4.455882    5.000000   \n",
            "A1GI0U000008ZRJA12   4.433962   3.000000   4.213198   5.000000    4.477876   \n",
            "...                       ...        ...        ...        ...         ...   \n",
            "A1GI0U000299ZRJA13   5.000000   4.314815   4.213198   5.000000    5.000000   \n",
            "A1GI0U000300ZRJA14   4.000000   4.000000   5.000000   4.455882    5.000000   \n",
            "A1GI0U000301ZRJA15   5.000000   5.000000   4.000000   5.000000    4.000000   \n",
            "A1GI0U000302ZRJA16   5.000000   5.000000   2.000000   4.455882    4.000000   \n",
            "A1GI0U000303ZRJA17   5.000000   4.314815   5.000000   4.455882    5.000000   \n",
            "\n",
            "                    Product_11  Product_12  Product_13  Product_14  \\\n",
            "A1GI0U000004ZRJA8     5.000000    4.000000    5.000000    5.000000   \n",
            "A1GI0U000005ZRJA9     3.000000    5.000000    4.412844    4.451456   \n",
            "A1GI0U000006ZRJA10    4.209524    4.458515    5.000000    5.000000   \n",
            "A1GI0U000007ZRJA11    3.000000    5.000000    5.000000    4.451456   \n",
            "A1GI0U000008ZRJA12    5.000000    5.000000    4.000000    5.000000   \n",
            "...                        ...         ...         ...         ...   \n",
            "A1GI0U000299ZRJA13    4.209524    5.000000    5.000000    2.000000   \n",
            "A1GI0U000300ZRJA14    4.000000    5.000000    5.000000    4.451456   \n",
            "A1GI0U000301ZRJA15    5.000000    5.000000    5.000000    4.000000   \n",
            "A1GI0U000302ZRJA16    4.209524    5.000000    4.412844    5.000000   \n",
            "A1GI0U000303ZRJA17    4.209524    5.000000    4.412844    5.000000   \n",
            "\n",
            "                    Product_15  Product_16  Product_17  Product_18  \\\n",
            "A1GI0U000004ZRJA8     4.277273    4.346341    4.000000    5.000000   \n",
            "A1GI0U000005ZRJA9     3.000000    5.000000    4.334821    4.252381   \n",
            "A1GI0U000006ZRJA10    4.277273    5.000000    5.000000    5.000000   \n",
            "A1GI0U000007ZRJA11    5.000000    3.000000    5.000000    4.252381   \n",
            "A1GI0U000008ZRJA12    5.000000    5.000000    5.000000    4.252381   \n",
            "...                        ...         ...         ...         ...   \n",
            "A1GI0U000299ZRJA13    4.277273    4.346341    5.000000    3.000000   \n",
            "A1GI0U000300ZRJA14    5.000000    4.000000    5.000000    3.000000   \n",
            "A1GI0U000301ZRJA15    4.277273    4.346341    3.000000    5.000000   \n",
            "A1GI0U000302ZRJA16    4.000000    2.000000    5.000000    5.000000   \n",
            "A1GI0U000303ZRJA17    2.000000    4.346341    4.000000    4.252381   \n",
            "\n",
            "                    Product_19  Product_20  \n",
            "A1GI0U000004ZRJA8     5.000000    4.357488  \n",
            "A1GI0U000005ZRJA9     4.316742    5.000000  \n",
            "A1GI0U000006ZRJA10    5.000000    4.357488  \n",
            "A1GI0U000007ZRJA11    4.316742    5.000000  \n",
            "A1GI0U000008ZRJA12    5.000000    3.000000  \n",
            "...                        ...         ...  \n",
            "A1GI0U000299ZRJA13    5.000000    5.000000  \n",
            "A1GI0U000300ZRJA14    5.000000    5.000000  \n",
            "A1GI0U000301ZRJA15    5.000000    4.357488  \n",
            "A1GI0U000302ZRJA16    4.316742    4.357488  \n",
            "A1GI0U000303ZRJA17    2.000000    4.357488  \n",
            "\n",
            "[300 rows x 20 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compute the covariance matrix\n",
        "cov_matrix = np.cov(df_filled.T)\n",
        "\n",
        "# Calculate eigenvalues and eigenvectors\n",
        "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
        "\n",
        "print(\"Eigenvalues:\")\n",
        "print(eigenvalues)\n",
        "\n",
        "print(\"Eigenvectors:\")\n",
        "print(eigenvectors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJDfReIDtYsy",
        "outputId": "95bcfa59-9f32-4c4c-e859-22623b26f1d3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues:\n",
            "[1.37233871 1.33215769 0.512919   0.5537903  0.61059109 0.62415772\n",
            " 1.21433507 1.19220313 1.15771291 0.68998451 0.71506391 0.76430046\n",
            " 0.78605991 0.81170376 0.9220175  0.92987218 1.03601124 0.98200015\n",
            " 1.01616917 1.00368592]\n",
            "Eigenvectors:\n",
            "[[ 0.22377306  0.27245978  0.30616035  0.09175753  0.46836152 -0.41398254\n",
            "   0.01579683 -0.16035603  0.008662    0.30490198 -0.29122942  0.06167975\n",
            "   0.30138141 -0.07515112 -0.15695302 -0.13286756 -0.05525479  0.09455525\n",
            "   0.07669722  0.13611789]\n",
            " [ 0.25512566  0.32371509 -0.05181385 -0.32165919  0.16095747 -0.10709065\n",
            "   0.10581016 -0.03506029 -0.38068816 -0.38000825  0.17503245  0.03846577\n",
            "  -0.24647781  0.04366868  0.00142535 -0.21447582 -0.11029056  0.25265877\n",
            "  -0.40482105 -0.06467582]\n",
            " [-0.02035508 -0.07031166 -0.1678239  -0.03649735  0.17373506 -0.13645559\n",
            "  -0.02786497 -0.50917516  0.18864625 -0.02444505 -0.14615203 -0.18621898\n",
            "  -0.3434516  -0.0657595  -0.26286997  0.36072277  0.29815405 -0.221498\n",
            "  -0.32324702  0.0114736 ]\n",
            " [ 0.4918325   0.34364796 -0.05725464 -0.0163878  -0.13581112  0.19056997\n",
            "  -0.03531162 -0.10274388  0.38046915 -0.3513709  -0.1467791   0.02588675\n",
            "  -0.05583103  0.11987248  0.01416191  0.21629465 -0.24753624 -0.07621449\n",
            "   0.3328919   0.1925944 ]\n",
            " [ 0.04462034 -0.04421135  0.08207913  0.28857218 -0.26125756  0.07366383\n",
            "   0.00130581  0.22535304 -0.01687057 -0.04512504 -0.14670229  0.00926901\n",
            "   0.24132824  0.32488839 -0.46489444  0.21221489 -0.08294253  0.23756663\n",
            "  -0.48037705  0.19650522]\n",
            " [-0.02547382  0.05457617  0.54198637 -0.10812758  0.09800359  0.48523777\n",
            "   0.12535096 -0.30942316 -0.085519   -0.09986136  0.14780865  0.08983566\n",
            "   0.18743679  0.14728306 -0.09271005  0.14517694  0.33119443  0.11655404\n",
            "   0.10885618 -0.25610845]\n",
            " [ 0.023258   -0.10320457  0.12873374  0.02686445  0.06888783 -0.34057035\n",
            "   0.08184975  0.20193189  0.43215075 -0.2246842   0.34551343 -0.1702215\n",
            "  -0.05445648  0.15756681  0.08325763 -0.09000996  0.4568976   0.31812394\n",
            "   0.08740022  0.23935036]\n",
            " [-0.17306704  0.55965337 -0.04721889  0.20068207  0.1172298   0.16776785\n",
            "  -0.30157467  0.16141693  0.04402462  0.31332021  0.39985011  0.23740205\n",
            "  -0.23323172 -0.09375908 -0.05400302  0.18962876  0.09469226  0.01528412\n",
            "  -0.05574994  0.15723341]\n",
            " [ 0.3507782   0.12986967 -0.141041   -0.2839914  -0.1938735   0.03041263\n",
            "   0.21796057  0.04639902  0.17904023  0.34902882  0.37740882 -0.26508728\n",
            "   0.37388175 -0.09247309 -0.10682555 -0.05941376  0.06522666 -0.28302669\n",
            "  -0.20209612 -0.12769533]\n",
            " [-0.0945583   0.10083871 -0.56303895  0.08794709  0.01934758  0.04703402\n",
            "   0.10122625 -0.15636596 -0.06411498 -0.23946286 -0.03954686  0.24008894\n",
            "   0.4725816  -0.32629849 -0.04035052  0.05092418  0.28401612  0.27278539\n",
            "   0.08526051  0.04274819]\n",
            " [-0.40500412  0.29027027  0.05705187 -0.1810302  -0.13322305 -0.1324081\n",
            "   0.45368317  0.20900588  0.19576291 -0.10920009 -0.15366855  0.12697855\n",
            "  -0.16196711 -0.07700272 -0.46365421 -0.11970317 -0.02866713 -0.12447279\n",
            "   0.17153696 -0.1835849 ]\n",
            " [-0.10487212 -0.16791947  0.00550399 -0.14457347  0.03673647 -0.40272923\n",
            "  -0.08559683 -0.14670261  0.08377657 -0.11758891  0.36286143  0.51482207\n",
            "   0.2118927   0.26093583  0.00373217  0.29620678 -0.28043719 -0.17954625\n",
            "  -0.00918763 -0.13499515]\n",
            " [ 0.14378475 -0.09887833  0.25319305  0.53193166  0.0631447   0.00463714\n",
            "   0.06133341  0.04205925  0.15110758 -0.32605193  0.1986273   0.04492718\n",
            "  -0.00572891 -0.53325416 -0.02841093 -0.09505136 -0.14655828 -0.19198861\n",
            "  -0.20136017 -0.22184958]\n",
            " [-0.0010883  -0.08597124 -0.27594417  0.19537093  0.59316392  0.18402647\n",
            "   0.11257225  0.20815063 -0.15742203 -0.15555096  0.15904937 -0.21221203\n",
            "   0.06981284  0.3426515  -0.24107086 -0.04837463 -0.04425624 -0.31282311\n",
            "   0.18590683  0.01259118]\n",
            " [-0.20914651  0.11234735  0.08335259  0.10473046  0.06412649  0.04532105\n",
            "   0.63621508 -0.07494565 -0.05339176  0.03477754  0.01212067 -0.04538061\n",
            "   0.04457447  0.0151516   0.4596448   0.25910986 -0.14241527 -0.1041209\n",
            "  -0.18193612  0.3975535 ]\n",
            " [-0.11470803  0.29527616  0.03195237  0.28305864 -0.29280644 -0.35480146\n",
            "  -0.05972631 -0.16054494 -0.35231833 -0.10014786  0.14784816 -0.49239748\n",
            "   0.07721151  0.07996008  0.00092984  0.22590344 -0.03335526  0.03010231\n",
            "   0.25758323 -0.21753356]\n",
            " [ 0.00704482  0.08047817  0.13827934  0.0318194  -0.26615024 -0.07890492\n",
            "  -0.13778125 -0.09349751 -0.26889437 -0.19497051 -0.01211459  0.18455908\n",
            "   0.0785367   0.06762608 -0.04555116 -0.32899747  0.3440822  -0.54475664\n",
            "  -0.008211    0.43330216]\n",
            " [-0.12742121 -0.20441992  0.01466966 -0.04863116 -0.07261997  0.1162919\n",
            "   0.03305213 -0.41009002 -0.01570816  0.07214675  0.35508405 -0.12259613\n",
            "  -0.07118959 -0.16000348 -0.36216427 -0.22445505 -0.36916767  0.21689861\n",
            "   0.17885549  0.4209927 ]\n",
            " [-0.40490435  0.14458976  0.1456825  -0.33922928  0.16964282  0.07837634\n",
            "  -0.39586633  0.0999762   0.18393357 -0.294384   -0.07608234 -0.34078796\n",
            "   0.33888191 -0.16123568  0.07635192  0.03859285 -0.17144019 -0.08875795\n",
            "  -0.18759415  0.11909154]\n",
            " [ 0.2111115  -0.20857508  0.15452861 -0.27898007  0.04612001 -0.08135666\n",
            "   0.02652998  0.36698247 -0.34041507 -0.03697732  0.03093004  0.00149967\n",
            "  -0.05850254 -0.39910564 -0.18493061  0.50142312  0.08386556 -0.02234549\n",
            "   0.20529545  0.22332374]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if eigenvectors are mutually orthogonal\n",
        "orthogonality_check = np.allclose(np.dot(eigenvectors.T, eigenvectors), np.eye(eigenvectors.shape[1]))\n",
        "\n",
        "if orthogonality_check:\n",
        "    print(\"Eigenvectors are orthogonal.\")\n",
        "else:\n",
        "    print(\"Eigenvectors are not orthogonal.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YYsu_obtaxg",
        "outputId": "3a4befa5-3d23-4476-d695-a1127a9b129f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvectors are orthogonal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize each eigenvector\n",
        "eigenvectors_normalized = eigenvectors / np.linalg.norm(eigenvectors, axis=0)\n",
        "\n",
        "print(\"Normalized Eigenvectors:\")\n",
        "print(eigenvectors_normalized)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVytvhtlteWy",
        "outputId": "7232b042-491e-4130-9d0d-ea5938dac9a5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Eigenvectors:\n",
            "[[ 0.22377306  0.27245978  0.30616035  0.09175753  0.46836152 -0.41398254\n",
            "   0.01579683 -0.16035603  0.008662    0.30490198 -0.29122942  0.06167975\n",
            "   0.30138141 -0.07515112 -0.15695302 -0.13286756 -0.05525479  0.09455525\n",
            "   0.07669722  0.13611789]\n",
            " [ 0.25512566  0.32371509 -0.05181385 -0.32165919  0.16095747 -0.10709065\n",
            "   0.10581016 -0.03506029 -0.38068816 -0.38000825  0.17503245  0.03846577\n",
            "  -0.24647781  0.04366868  0.00142535 -0.21447582 -0.11029056  0.25265877\n",
            "  -0.40482105 -0.06467582]\n",
            " [-0.02035508 -0.07031166 -0.1678239  -0.03649735  0.17373506 -0.13645559\n",
            "  -0.02786497 -0.50917516  0.18864625 -0.02444505 -0.14615203 -0.18621898\n",
            "  -0.3434516  -0.0657595  -0.26286997  0.36072277  0.29815405 -0.221498\n",
            "  -0.32324702  0.0114736 ]\n",
            " [ 0.4918325   0.34364796 -0.05725464 -0.0163878  -0.13581112  0.19056997\n",
            "  -0.03531162 -0.10274388  0.38046915 -0.3513709  -0.1467791   0.02588675\n",
            "  -0.05583103  0.11987248  0.01416191  0.21629465 -0.24753624 -0.07621449\n",
            "   0.3328919   0.1925944 ]\n",
            " [ 0.04462034 -0.04421135  0.08207913  0.28857218 -0.26125756  0.07366383\n",
            "   0.00130581  0.22535304 -0.01687057 -0.04512504 -0.14670229  0.00926901\n",
            "   0.24132824  0.32488839 -0.46489444  0.21221489 -0.08294253  0.23756663\n",
            "  -0.48037705  0.19650522]\n",
            " [-0.02547382  0.05457617  0.54198637 -0.10812758  0.09800359  0.48523777\n",
            "   0.12535096 -0.30942316 -0.085519   -0.09986136  0.14780865  0.08983566\n",
            "   0.18743679  0.14728306 -0.09271005  0.14517694  0.33119443  0.11655404\n",
            "   0.10885618 -0.25610845]\n",
            " [ 0.023258   -0.10320457  0.12873374  0.02686445  0.06888783 -0.34057035\n",
            "   0.08184975  0.20193189  0.43215075 -0.2246842   0.34551343 -0.1702215\n",
            "  -0.05445648  0.15756681  0.08325763 -0.09000996  0.4568976   0.31812394\n",
            "   0.08740022  0.23935036]\n",
            " [-0.17306704  0.55965337 -0.04721889  0.20068207  0.1172298   0.16776785\n",
            "  -0.30157467  0.16141693  0.04402462  0.31332021  0.39985011  0.23740205\n",
            "  -0.23323172 -0.09375908 -0.05400302  0.18962876  0.09469226  0.01528412\n",
            "  -0.05574994  0.15723341]\n",
            " [ 0.3507782   0.12986967 -0.141041   -0.2839914  -0.1938735   0.03041263\n",
            "   0.21796057  0.04639902  0.17904023  0.34902882  0.37740882 -0.26508728\n",
            "   0.37388175 -0.09247309 -0.10682555 -0.05941376  0.06522666 -0.28302669\n",
            "  -0.20209612 -0.12769533]\n",
            " [-0.0945583   0.10083871 -0.56303895  0.08794709  0.01934758  0.04703402\n",
            "   0.10122625 -0.15636596 -0.06411498 -0.23946286 -0.03954686  0.24008894\n",
            "   0.4725816  -0.32629849 -0.04035052  0.05092418  0.28401612  0.27278539\n",
            "   0.08526051  0.04274819]\n",
            " [-0.40500412  0.29027027  0.05705187 -0.1810302  -0.13322305 -0.1324081\n",
            "   0.45368317  0.20900588  0.19576291 -0.10920009 -0.15366855  0.12697855\n",
            "  -0.16196711 -0.07700272 -0.46365421 -0.11970317 -0.02866713 -0.12447279\n",
            "   0.17153696 -0.1835849 ]\n",
            " [-0.10487212 -0.16791947  0.00550399 -0.14457347  0.03673647 -0.40272923\n",
            "  -0.08559683 -0.14670261  0.08377657 -0.11758891  0.36286143  0.51482207\n",
            "   0.2118927   0.26093583  0.00373217  0.29620678 -0.28043719 -0.17954625\n",
            "  -0.00918763 -0.13499515]\n",
            " [ 0.14378475 -0.09887833  0.25319305  0.53193166  0.0631447   0.00463714\n",
            "   0.06133341  0.04205925  0.15110758 -0.32605193  0.1986273   0.04492718\n",
            "  -0.00572891 -0.53325416 -0.02841093 -0.09505136 -0.14655828 -0.19198861\n",
            "  -0.20136017 -0.22184958]\n",
            " [-0.0010883  -0.08597124 -0.27594417  0.19537093  0.59316392  0.18402647\n",
            "   0.11257225  0.20815063 -0.15742203 -0.15555096  0.15904937 -0.21221203\n",
            "   0.06981284  0.3426515  -0.24107086 -0.04837463 -0.04425624 -0.31282311\n",
            "   0.18590683  0.01259118]\n",
            " [-0.20914651  0.11234735  0.08335259  0.10473046  0.06412649  0.04532105\n",
            "   0.63621508 -0.07494565 -0.05339176  0.03477754  0.01212067 -0.04538061\n",
            "   0.04457447  0.0151516   0.4596448   0.25910986 -0.14241527 -0.1041209\n",
            "  -0.18193612  0.3975535 ]\n",
            " [-0.11470803  0.29527616  0.03195237  0.28305864 -0.29280644 -0.35480146\n",
            "  -0.05972631 -0.16054494 -0.35231833 -0.10014786  0.14784816 -0.49239748\n",
            "   0.07721151  0.07996008  0.00092984  0.22590344 -0.03335526  0.03010231\n",
            "   0.25758323 -0.21753356]\n",
            " [ 0.00704482  0.08047817  0.13827934  0.0318194  -0.26615024 -0.07890492\n",
            "  -0.13778125 -0.09349751 -0.26889437 -0.19497051 -0.01211459  0.18455908\n",
            "   0.0785367   0.06762608 -0.04555116 -0.32899747  0.3440822  -0.54475664\n",
            "  -0.008211    0.43330216]\n",
            " [-0.12742121 -0.20441992  0.01466966 -0.04863116 -0.07261997  0.1162919\n",
            "   0.03305213 -0.41009002 -0.01570816  0.07214675  0.35508405 -0.12259613\n",
            "  -0.07118959 -0.16000348 -0.36216427 -0.22445505 -0.36916767  0.21689861\n",
            "   0.17885549  0.4209927 ]\n",
            " [-0.40490435  0.14458976  0.1456825  -0.33922928  0.16964282  0.07837634\n",
            "  -0.39586633  0.0999762   0.18393357 -0.294384   -0.07608234 -0.34078796\n",
            "   0.33888191 -0.16123568  0.07635192  0.03859285 -0.17144019 -0.08875795\n",
            "  -0.18759415  0.11909154]\n",
            " [ 0.2111115  -0.20857508  0.15452861 -0.27898007  0.04612001 -0.08135666\n",
            "   0.02652998  0.36698247 -0.34041507 -0.03697732  0.03093004  0.00149967\n",
            "  -0.05850254 -0.39910564 -0.18493061  0.50142312  0.08386556 -0.02234549\n",
            "   0.20529545  0.22332374]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if eigenvectors are orthonormal (magnitude of 1 and mutually orthogonal)\n",
        "orthonormality_check = np.allclose(np.dot(eigenvectors_normalized.T, eigenvectors_normalized), np.eye(eigenvectors_normalized.shape[1]))\n",
        "\n",
        "if orthonormality_check:\n",
        "    print(\"Eigenvectors are orthonormal.\")\n",
        "else:\n",
        "    print(\"Eigenvectors are not orthonormal.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGFDee7KtgtP",
        "outputId": "cd52666a-8ec1-46ec-f49a-1349339928e8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvectors are orthonormal.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume the first orthonormal vector is the eigenvector with the highest eigenvalue\n",
        "u1 = eigenvectors_normalized[:, np.argmax(eigenvalues)]\n",
        "\n",
        "print(\"First Orthonormal Vector (u1):\")\n",
        "print(u1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iuu6QOr_titW",
        "outputId": "46d0c076-f208-4b11-f0c8-676afabef477"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Orthonormal Vector (u1):\n",
            "[ 0.22377306  0.25512566 -0.02035508  0.4918325   0.04462034 -0.02547382\n",
            "  0.023258   -0.17306704  0.3507782  -0.0945583  -0.40500412 -0.10487212\n",
            "  0.14378475 -0.0010883  -0.20914651 -0.11470803  0.00704482 -0.12742121\n",
            " -0.40490435  0.2111115 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e1 = u1 / np.linalg.norm(u1)\n",
        "\n",
        "print(\"Normalized u1 (e1):\")\n",
        "print(e1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmJJo_wmtixh",
        "outputId": "487e898e-8d73-467d-de82-5c5ad895b09b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized u1 (e1):\n",
            "[ 0.22377306  0.25512566 -0.02035508  0.4918325   0.04462034 -0.02547382\n",
            "  0.023258   -0.17306704  0.3507782  -0.0945583  -0.40500412 -0.10487212\n",
            "  0.14378475 -0.0010883  -0.20914651 -0.11470803  0.00704482 -0.12742121\n",
            " -0.40490435  0.2111115 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigma1 = max(eigenvalues)\n",
        "\n",
        "print(\"Highest Eigenvalue (σ1):\")\n",
        "print(sigma1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di4pT-ZQtnYs",
        "outputId": "85564a92-e23a-4c14-de7a-e25f94393e1f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Highest Eigenvalue (σ1):\n",
            "1.372338706278186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u1_hat = sigma1 * e1\n",
        "\n",
        "print(\"Predicted Vector (u1_hat):\")\n",
        "print(u1_hat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbcxZQfhtpMO",
        "outputId": "ca157387-3510-4613-eefd-400d3507ef1a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Vector (u1_hat):\n",
            "[ 0.30709243  0.35011882 -0.02793407  0.67496078  0.06123423 -0.03495871\n",
            "  0.03191786 -0.2375066   0.4813865  -0.12976602 -0.55580283 -0.14392007\n",
            "  0.19732138 -0.00149352 -0.28701985 -0.15741827  0.00966788 -0.17486506\n",
            " -0.55566591  0.28971649]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v2 = eigenvectors_normalized[:, 1]  # Assume v2 is the second eigenvector\n",
        "proj_u1_v2 = np.dot(v2, e1) * e1\n",
        "\n",
        "print(\"Projection of u1 on v2 (Proj_u1_v2):\")\n",
        "print(proj_u1_v2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H47TlDstq4J",
        "outputId": "23d4fec8-5513-4222-8bd2-31a64364d024"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Projection of u1 on v2 (Proj_u1_v2):\n",
            "[ 1.39746377e-16  1.59326089e-16 -1.27117576e-17  3.07149621e-16\n",
            "  2.78654255e-17 -1.59084134e-17  1.45246331e-17 -1.08080447e-16\n",
            "  2.19061146e-16 -5.90517011e-17 -2.52925257e-16 -6.54926864e-17\n",
            "  8.97936421e-17 -6.79645751e-19 -1.30612090e-16 -7.16352184e-17\n",
            "  4.39949194e-18 -7.95746061e-17 -2.52862948e-16  1.31839228e-16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u2 = v2 - proj_u1_v2\n",
        "\n",
        "print(\"New Orthonormal Vector (u2):\")\n",
        "print(u2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvH8s95Ntsfh",
        "outputId": "a6de0dd9-2ff8-4222-eb37-db94f71fe38e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Orthonormal Vector (u2):\n",
            "[ 0.27245978  0.32371509 -0.07031166  0.34364796 -0.04421135  0.05457617\n",
            " -0.10320457  0.55965337  0.12986967  0.10083871  0.29027027 -0.16791947\n",
            " -0.09887833 -0.08597124  0.11234735  0.29527616  0.08047817 -0.20441992\n",
            "  0.14458976 -0.20857508]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e2 = u2 / np.linalg.norm(u2)\n",
        "\n",
        "print(\"Normalized u2 (e2):\")\n",
        "print(e2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7Hy04wrtugn",
        "outputId": "4dd8b090-6b5e-4ffd-c300-d65e17f5218b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized u2 (e2):\n",
            "[ 0.27245978  0.32371509 -0.07031166  0.34364796 -0.04421135  0.05457617\n",
            " -0.10320457  0.55965337  0.12986967  0.10083871  0.29027027 -0.16791947\n",
            " -0.09887833 -0.08597124  0.11234735  0.29527616  0.08047817 -0.20441992\n",
            "  0.14458976 -0.20857508]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigma2 = np.sqrt(np.dot(e2.T, np.dot(cov_matrix, e2)))\n",
        "\n",
        "print(\"New Eigenvalue (σ2):\")\n",
        "print(sigma2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsy7vIYftweJ",
        "outputId": "bd5888a8-c459-472e-944d-08a9e6468d54"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Eigenvalue (σ2):\n",
            "1.1541913566977033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u2_hat = sigma2 * e2\n",
        "\n",
        "print(\"Predicted Vector (u2_hat):\")\n",
        "print(u2_hat)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acQaV7AhtyFA",
        "outputId": "c0dd9a53-d4f7-45ef-b517-63af065e8f96"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Vector (u2_hat):\n",
            "[ 0.31447072  0.37362916 -0.08115311  0.3966355  -0.05102836  0.06299135\n",
            " -0.11911783  0.64594709  0.14989445  0.11638717  0.33502744 -0.1938112\n",
            " -0.11412452 -0.09922727  0.12967034  0.3408052   0.09288721 -0.23593971\n",
            "  0.16688425 -0.24073555]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the rest of the normalized orthonormal vectors and corresponding new eigenvalues\n",
        "orthonormal_vectors = []\n",
        "predicted_vectors = []\n",
        "new_eigenvalues = []\n",
        "\n",
        "for i in range(len(eigenvectors_normalized.T)):\n",
        "    v = eigenvectors_normalized[:, i]\n",
        "    e = v / np.linalg.norm(v)  # Normalize the eigenvector\n",
        "    sigma = np.sqrt(np.dot(e.T, np.dot(cov_matrix, e)))  # Compute the new eigenvalue\n",
        "    u_hat = sigma * e  # Predicted vector\n",
        "\n",
        "    orthonormal_vectors.append(e)\n",
        "    predicted_vectors.append(u_hat)\n",
        "    new_eigenvalues.append(sigma)\n",
        "\n",
        "orthonormal_vectors = np.array(orthonormal_vectors).T\n",
        "predicted_vectors = np.array(predicted_vectors).T\n",
        "\n",
        "print(\"Orthonormal Vectors:\")\n",
        "print(orthonormal_vectors)\n",
        "\n",
        "print(\"Predicted Vectors:\")\n",
        "print(predicted_vectors)\n",
        "\n",
        "print(\"New Eigenvalues:\")\n",
        "print(new_eigenvalues)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0aQJ2IPuGBG",
        "outputId": "7608c23b-ed6a-4025-8ae3-d0673f3ed635"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Orthonormal Vectors:\n",
            "[[ 0.22377306  0.27245978  0.30616035  0.09175753  0.46836152 -0.41398254\n",
            "   0.01579683 -0.16035603  0.008662    0.30490198 -0.29122942  0.06167975\n",
            "   0.30138141 -0.07515112 -0.15695302 -0.13286756 -0.05525479  0.09455525\n",
            "   0.07669722  0.13611789]\n",
            " [ 0.25512566  0.32371509 -0.05181385 -0.32165919  0.16095747 -0.10709065\n",
            "   0.10581016 -0.03506029 -0.38068816 -0.38000825  0.17503245  0.03846577\n",
            "  -0.24647781  0.04366868  0.00142535 -0.21447582 -0.11029056  0.25265877\n",
            "  -0.40482105 -0.06467582]\n",
            " [-0.02035508 -0.07031166 -0.1678239  -0.03649735  0.17373506 -0.13645559\n",
            "  -0.02786497 -0.50917516  0.18864625 -0.02444505 -0.14615203 -0.18621898\n",
            "  -0.3434516  -0.0657595  -0.26286997  0.36072277  0.29815405 -0.221498\n",
            "  -0.32324702  0.0114736 ]\n",
            " [ 0.4918325   0.34364796 -0.05725464 -0.0163878  -0.13581112  0.19056997\n",
            "  -0.03531162 -0.10274388  0.38046915 -0.3513709  -0.1467791   0.02588675\n",
            "  -0.05583103  0.11987248  0.01416191  0.21629465 -0.24753624 -0.07621449\n",
            "   0.3328919   0.1925944 ]\n",
            " [ 0.04462034 -0.04421135  0.08207913  0.28857218 -0.26125756  0.07366383\n",
            "   0.00130581  0.22535304 -0.01687057 -0.04512504 -0.14670229  0.00926901\n",
            "   0.24132824  0.32488839 -0.46489444  0.21221489 -0.08294253  0.23756663\n",
            "  -0.48037705  0.19650522]\n",
            " [-0.02547382  0.05457617  0.54198637 -0.10812758  0.09800359  0.48523777\n",
            "   0.12535096 -0.30942316 -0.085519   -0.09986136  0.14780865  0.08983566\n",
            "   0.18743679  0.14728306 -0.09271005  0.14517694  0.33119443  0.11655404\n",
            "   0.10885618 -0.25610845]\n",
            " [ 0.023258   -0.10320457  0.12873374  0.02686445  0.06888783 -0.34057035\n",
            "   0.08184975  0.20193189  0.43215075 -0.2246842   0.34551343 -0.1702215\n",
            "  -0.05445648  0.15756681  0.08325763 -0.09000996  0.4568976   0.31812394\n",
            "   0.08740022  0.23935036]\n",
            " [-0.17306704  0.55965337 -0.04721889  0.20068207  0.1172298   0.16776785\n",
            "  -0.30157467  0.16141693  0.04402462  0.31332021  0.39985011  0.23740205\n",
            "  -0.23323172 -0.09375908 -0.05400302  0.18962876  0.09469226  0.01528412\n",
            "  -0.05574994  0.15723341]\n",
            " [ 0.3507782   0.12986967 -0.141041   -0.2839914  -0.1938735   0.03041263\n",
            "   0.21796057  0.04639902  0.17904023  0.34902882  0.37740882 -0.26508728\n",
            "   0.37388175 -0.09247309 -0.10682555 -0.05941376  0.06522666 -0.28302669\n",
            "  -0.20209612 -0.12769533]\n",
            " [-0.0945583   0.10083871 -0.56303895  0.08794709  0.01934758  0.04703402\n",
            "   0.10122625 -0.15636596 -0.06411498 -0.23946286 -0.03954686  0.24008894\n",
            "   0.4725816  -0.32629849 -0.04035052  0.05092418  0.28401612  0.27278539\n",
            "   0.08526051  0.04274819]\n",
            " [-0.40500412  0.29027027  0.05705187 -0.1810302  -0.13322305 -0.1324081\n",
            "   0.45368317  0.20900588  0.19576291 -0.10920009 -0.15366855  0.12697855\n",
            "  -0.16196711 -0.07700272 -0.46365421 -0.11970317 -0.02866713 -0.12447279\n",
            "   0.17153696 -0.1835849 ]\n",
            " [-0.10487212 -0.16791947  0.00550399 -0.14457347  0.03673647 -0.40272923\n",
            "  -0.08559683 -0.14670261  0.08377657 -0.11758891  0.36286143  0.51482207\n",
            "   0.2118927   0.26093583  0.00373217  0.29620678 -0.28043719 -0.17954625\n",
            "  -0.00918763 -0.13499515]\n",
            " [ 0.14378475 -0.09887833  0.25319305  0.53193166  0.0631447   0.00463714\n",
            "   0.06133341  0.04205925  0.15110758 -0.32605193  0.1986273   0.04492718\n",
            "  -0.00572891 -0.53325416 -0.02841093 -0.09505136 -0.14655828 -0.19198861\n",
            "  -0.20136017 -0.22184958]\n",
            " [-0.0010883  -0.08597124 -0.27594417  0.19537093  0.59316392  0.18402647\n",
            "   0.11257225  0.20815063 -0.15742203 -0.15555096  0.15904937 -0.21221203\n",
            "   0.06981284  0.3426515  -0.24107086 -0.04837463 -0.04425624 -0.31282311\n",
            "   0.18590683  0.01259118]\n",
            " [-0.20914651  0.11234735  0.08335259  0.10473046  0.06412649  0.04532105\n",
            "   0.63621508 -0.07494565 -0.05339176  0.03477754  0.01212067 -0.04538061\n",
            "   0.04457447  0.0151516   0.4596448   0.25910986 -0.14241527 -0.1041209\n",
            "  -0.18193612  0.3975535 ]\n",
            " [-0.11470803  0.29527616  0.03195237  0.28305864 -0.29280644 -0.35480146\n",
            "  -0.05972631 -0.16054494 -0.35231833 -0.10014786  0.14784816 -0.49239748\n",
            "   0.07721151  0.07996008  0.00092984  0.22590344 -0.03335526  0.03010231\n",
            "   0.25758323 -0.21753356]\n",
            " [ 0.00704482  0.08047817  0.13827934  0.0318194  -0.26615024 -0.07890492\n",
            "  -0.13778125 -0.09349751 -0.26889437 -0.19497051 -0.01211459  0.18455908\n",
            "   0.0785367   0.06762608 -0.04555116 -0.32899747  0.3440822  -0.54475664\n",
            "  -0.008211    0.43330216]\n",
            " [-0.12742121 -0.20441992  0.01466966 -0.04863116 -0.07261997  0.1162919\n",
            "   0.03305213 -0.41009002 -0.01570816  0.07214675  0.35508405 -0.12259613\n",
            "  -0.07118959 -0.16000348 -0.36216427 -0.22445505 -0.36916767  0.21689861\n",
            "   0.17885549  0.4209927 ]\n",
            " [-0.40490435  0.14458976  0.1456825  -0.33922928  0.16964282  0.07837634\n",
            "  -0.39586633  0.0999762   0.18393357 -0.294384   -0.07608234 -0.34078796\n",
            "   0.33888191 -0.16123568  0.07635192  0.03859285 -0.17144019 -0.08875795\n",
            "  -0.18759415  0.11909154]\n",
            " [ 0.2111115  -0.20857508  0.15452861 -0.27898007  0.04612001 -0.08135666\n",
            "   0.02652998  0.36698247 -0.34041507 -0.03697732  0.03093004  0.00149967\n",
            "  -0.05850254 -0.39910564 -0.18493061  0.50142312  0.08386556 -0.02234549\n",
            "   0.20529545  0.22332374]]\n",
            "Predicted Vectors:\n",
            "[[ 0.26214312  0.31447072  0.21926704  0.06828328  0.36597923 -0.32706133\n",
            "   0.01740762 -0.17508963  0.00932005  0.25326776 -0.24626782  0.05392308\n",
            "   0.26720482 -0.0677071  -0.15070903 -0.12812403 -0.05624088  0.0937004\n",
            "   0.0773148   0.13636852]\n",
            " [ 0.2988717   0.37362916 -0.03710823 -0.2393694   0.1257727  -0.08460552\n",
            "   0.11659949 -0.03828165 -0.4096093  -0.31565502  0.14800998  0.03362842\n",
            "  -0.21852727  0.03934312  0.00136865 -0.20681878 -0.11225885  0.25037454\n",
            "  -0.40808074 -0.06479491]\n",
            " [-0.02384534 -0.08115311 -0.12019273 -0.02716026  0.13575714 -0.1078049\n",
            "  -0.03070632 -0.55595845  0.20297784 -0.02030535 -0.12358828 -0.1628006\n",
            "  -0.30450425 -0.05924576 -0.25241232  0.34784454  0.30347502 -0.21949548\n",
            "  -0.32584986  0.01149472]\n",
            " [ 0.57616634  0.3966355  -0.04100484 -0.01219532 -0.10612325  0.15055724\n",
            "  -0.0389123  -0.11218404  0.40937365 -0.29186731 -0.12411854  0.02263131\n",
            "  -0.0494998   0.10799864  0.01359851  0.20857267 -0.25195387 -0.07552545\n",
            "   0.3355724   0.19294902]\n",
            " [ 0.05227133 -0.05102836  0.05878373  0.21474701 -0.20414751  0.05819712\n",
            "   0.00143897  0.24605861 -0.01815223 -0.03748325 -0.12405359  0.00810337\n",
            "   0.21396166  0.29270691 -0.44639974  0.20463856 -0.08442276  0.23541884\n",
            "  -0.48424513  0.19686704]\n",
            " [-0.02984178  0.06299135  0.38816177 -0.0804654   0.07658033  0.38335557\n",
            "   0.13813283 -0.33785313 -0.09201594 -0.08295014  0.12498914  0.07853818\n",
            "   0.16618149  0.13269409 -0.08902181  0.13999395  0.33710504  0.1155003\n",
            "   0.10973271 -0.25658001]\n",
            " [ 0.02724602 -0.11911783  0.092197    0.01999174  0.05382917 -0.26906302\n",
            "   0.09019586  0.2204855   0.46498154 -0.18663462  0.29217117 -0.14881492\n",
            "  -0.04828113  0.14195919  0.07994543 -0.0867965   0.46505156  0.31524785\n",
            "   0.08810398  0.23979107]\n",
            " [-0.20274261  0.64594709 -0.0338174   0.14934175  0.09160375  0.13254273\n",
            "  -0.33232586  0.17624801  0.0473692   0.26026039  0.33811906  0.20754703\n",
            "  -0.20678329 -0.08447187 -0.05185464  0.18285879  0.09638217  0.01514594\n",
            "  -0.05619885  0.15752292]\n",
            " [ 0.41092565  0.14989445 -0.10101126 -0.21133813 -0.15149339  0.02402709\n",
            "   0.24018573  0.05066218  0.19264203  0.28992186  0.31914238 -0.23175064\n",
            "   0.33148364 -0.08331326 -0.10257576 -0.05729262  0.06639072 -0.28046791\n",
            "  -0.20372344 -0.12793045]\n",
            " [-0.11077208  0.11638717 -0.40323928  0.06544766  0.01511826  0.03715859\n",
            "   0.11154816 -0.17073295 -0.06898584 -0.19891056 -0.0334414   0.20989602\n",
            "   0.41899094 -0.29397734 -0.03874528  0.04910612  0.28908478  0.27031919\n",
            "   0.08594705  0.0428269 ]\n",
            " [-0.47444962  0.33502744  0.04085961 -0.1347174  -0.10410093 -0.10460724\n",
            "   0.49994466  0.22820945  0.21063516 -0.09070739 -0.12994436  0.11101008\n",
            "  -0.14360008 -0.0693753  -0.44520886 -0.11542962 -0.02917874 -0.12334745\n",
            "   0.1729182  -0.18392292]\n",
            " [-0.1228544  -0.1938112   0.00394187 -0.10758737  0.028706   -0.31817081\n",
            "  -0.09432503 -0.16018173  0.09014113 -0.09767558  0.30684089  0.45007948\n",
            "   0.18786411  0.23508911  0.0035837   0.28563184 -0.28544197 -0.17792301\n",
            "  -0.00926161 -0.13524371]\n",
            " [ 0.16843932 -0.11412452  0.18133272  0.39584805  0.04934147  0.00366351\n",
            "   0.06758749  0.04592368  0.16258732 -0.27083604  0.16796213  0.03927726\n",
            "  -0.00507925 -0.48043322 -0.02728067 -0.09165791 -0.14917381 -0.19025288\n",
            "  -0.20298156 -0.22225807]\n",
            " [-0.00127491 -0.09922727 -0.1976267   0.14538936  0.46350023  0.14538764\n",
            "   0.1240511   0.22727563 -0.16938149 -0.12920888  0.13449446 -0.18552484\n",
            "   0.06189608  0.30871051 -0.23148044 -0.04664759 -0.04504606 -0.30999494\n",
            "   0.18740378  0.01261437]\n",
            " [-0.24500857  0.12967034  0.05969576  0.07793736  0.05010865  0.03580528\n",
            "   0.70108912 -0.0818317  -0.05744797  0.02888807  0.01024941 -0.03967367\n",
            "   0.03951974  0.01365077  0.44135895  0.24985933 -0.14495687 -0.10317957\n",
            "  -0.1834011   0.39828551]\n",
            " [-0.13437686  0.3408052   0.02288376  0.210644   -0.22879991 -0.28030611\n",
            "  -0.06581653 -0.1752959  -0.3790842  -0.08318812  0.12502255 -0.43047495\n",
            "   0.06845574  0.07203972  0.00089285  0.21783841 -0.03395053  0.02983016\n",
            "   0.25965733 -0.21793409]\n",
            " [ 0.00825278  0.09288721  0.0990334   0.02367907 -0.20797067 -0.06233777\n",
            "  -0.15183063 -0.10208812 -0.28932246 -0.16195285 -0.01024427  0.16134945\n",
            "   0.06963065  0.06092745 -0.04373902 -0.31725186  0.35022282 -0.53983161\n",
            "  -0.00827711  0.43409999]\n",
            " [-0.14926995 -0.23593971  0.01050617 -0.03618989 -0.05674548  0.09187485\n",
            "   0.03642241 -0.44776932 -0.01690152  0.05992892  0.30026423 -0.10717879\n",
            "  -0.0631167  -0.1441545  -0.34775644 -0.21644174 -0.37575597  0.21493767\n",
            "   0.18029566  0.42176786]\n",
            " [-0.47433273  0.16688425  0.10433542 -0.25244455  0.13255946  0.06192017\n",
            "  -0.43623232  0.10916207  0.19790713 -0.24453097 -0.06433633 -0.29793142\n",
            "   0.30045277 -0.14526465  0.07331444  0.03721504 -0.17449978 -0.08795551\n",
            "  -0.18910469  0.11931082]\n",
            " [ 0.2473105  -0.24073555  0.11067086 -0.20760885  0.03603833 -0.06427473\n",
            "   0.02923521  0.40070102 -0.36627664 -0.03071532  0.02615489  0.00131108\n",
            "  -0.05186836 -0.35957265 -0.1775736   0.48352171  0.08536226 -0.02214347\n",
            "   0.20694852  0.22373494]]\n",
            "New Eigenvalues:\n",
            "[1.1714686108804555, 1.1541913566977033, 0.7161836383630246, 0.7441708788976041, 0.78140328107949, 0.7900365313455893, 1.1019687247080365, 1.0918805495327026, 1.0759706832328189, 0.8306530604258157, 0.8456145181695491, 0.874242793315054, 0.8866001949071536, 0.900946038073875, 0.9602174252595813, 0.9642988040714836, 1.0178463743970494, 0.9909592060005561, 1.0080521676808534, 1.0018412644494765]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the diagonal matrix \\Sigma from the new eigenvalues\n",
        "sigma_matrix = np.diag(new_eigenvalues)\n",
        "\n",
        "print(\"Predicted Weight Matrix (Σ):\")\n",
        "print(sigma_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyBwKcgfuIWm",
        "outputId": "527b35ec-79eb-4d5e-ff61-43921d9b2864"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Weight Matrix (Σ):\n",
            "[[1.17146861 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         1.15419136 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.71618364 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.74417088 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.78140328 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.79003653\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  1.10196872 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         1.09188055 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         1.07597068 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.83065306 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.84561452 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.87424279\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.88660019 0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.90094604 0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.96021743 0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.9642988  0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         1.01784637 0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.99095921\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  1.00805217 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         1.00184126]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the items matrix V from the orthonormal vectors\n",
        "items_matrix = orthonormal_vectors\n",
        "\n",
        "print(\"Items Matrix (V):\")\n",
        "print(items_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sun0_QAuKVt",
        "outputId": "7ab96e82-aa1b-4e11-e41a-70320f17a8c3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Items Matrix (V):\n",
            "[[ 0.22377306  0.27245978  0.30616035  0.09175753  0.46836152 -0.41398254\n",
            "   0.01579683 -0.16035603  0.008662    0.30490198 -0.29122942  0.06167975\n",
            "   0.30138141 -0.07515112 -0.15695302 -0.13286756 -0.05525479  0.09455525\n",
            "   0.07669722  0.13611789]\n",
            " [ 0.25512566  0.32371509 -0.05181385 -0.32165919  0.16095747 -0.10709065\n",
            "   0.10581016 -0.03506029 -0.38068816 -0.38000825  0.17503245  0.03846577\n",
            "  -0.24647781  0.04366868  0.00142535 -0.21447582 -0.11029056  0.25265877\n",
            "  -0.40482105 -0.06467582]\n",
            " [-0.02035508 -0.07031166 -0.1678239  -0.03649735  0.17373506 -0.13645559\n",
            "  -0.02786497 -0.50917516  0.18864625 -0.02444505 -0.14615203 -0.18621898\n",
            "  -0.3434516  -0.0657595  -0.26286997  0.36072277  0.29815405 -0.221498\n",
            "  -0.32324702  0.0114736 ]\n",
            " [ 0.4918325   0.34364796 -0.05725464 -0.0163878  -0.13581112  0.19056997\n",
            "  -0.03531162 -0.10274388  0.38046915 -0.3513709  -0.1467791   0.02588675\n",
            "  -0.05583103  0.11987248  0.01416191  0.21629465 -0.24753624 -0.07621449\n",
            "   0.3328919   0.1925944 ]\n",
            " [ 0.04462034 -0.04421135  0.08207913  0.28857218 -0.26125756  0.07366383\n",
            "   0.00130581  0.22535304 -0.01687057 -0.04512504 -0.14670229  0.00926901\n",
            "   0.24132824  0.32488839 -0.46489444  0.21221489 -0.08294253  0.23756663\n",
            "  -0.48037705  0.19650522]\n",
            " [-0.02547382  0.05457617  0.54198637 -0.10812758  0.09800359  0.48523777\n",
            "   0.12535096 -0.30942316 -0.085519   -0.09986136  0.14780865  0.08983566\n",
            "   0.18743679  0.14728306 -0.09271005  0.14517694  0.33119443  0.11655404\n",
            "   0.10885618 -0.25610845]\n",
            " [ 0.023258   -0.10320457  0.12873374  0.02686445  0.06888783 -0.34057035\n",
            "   0.08184975  0.20193189  0.43215075 -0.2246842   0.34551343 -0.1702215\n",
            "  -0.05445648  0.15756681  0.08325763 -0.09000996  0.4568976   0.31812394\n",
            "   0.08740022  0.23935036]\n",
            " [-0.17306704  0.55965337 -0.04721889  0.20068207  0.1172298   0.16776785\n",
            "  -0.30157467  0.16141693  0.04402462  0.31332021  0.39985011  0.23740205\n",
            "  -0.23323172 -0.09375908 -0.05400302  0.18962876  0.09469226  0.01528412\n",
            "  -0.05574994  0.15723341]\n",
            " [ 0.3507782   0.12986967 -0.141041   -0.2839914  -0.1938735   0.03041263\n",
            "   0.21796057  0.04639902  0.17904023  0.34902882  0.37740882 -0.26508728\n",
            "   0.37388175 -0.09247309 -0.10682555 -0.05941376  0.06522666 -0.28302669\n",
            "  -0.20209612 -0.12769533]\n",
            " [-0.0945583   0.10083871 -0.56303895  0.08794709  0.01934758  0.04703402\n",
            "   0.10122625 -0.15636596 -0.06411498 -0.23946286 -0.03954686  0.24008894\n",
            "   0.4725816  -0.32629849 -0.04035052  0.05092418  0.28401612  0.27278539\n",
            "   0.08526051  0.04274819]\n",
            " [-0.40500412  0.29027027  0.05705187 -0.1810302  -0.13322305 -0.1324081\n",
            "   0.45368317  0.20900588  0.19576291 -0.10920009 -0.15366855  0.12697855\n",
            "  -0.16196711 -0.07700272 -0.46365421 -0.11970317 -0.02866713 -0.12447279\n",
            "   0.17153696 -0.1835849 ]\n",
            " [-0.10487212 -0.16791947  0.00550399 -0.14457347  0.03673647 -0.40272923\n",
            "  -0.08559683 -0.14670261  0.08377657 -0.11758891  0.36286143  0.51482207\n",
            "   0.2118927   0.26093583  0.00373217  0.29620678 -0.28043719 -0.17954625\n",
            "  -0.00918763 -0.13499515]\n",
            " [ 0.14378475 -0.09887833  0.25319305  0.53193166  0.0631447   0.00463714\n",
            "   0.06133341  0.04205925  0.15110758 -0.32605193  0.1986273   0.04492718\n",
            "  -0.00572891 -0.53325416 -0.02841093 -0.09505136 -0.14655828 -0.19198861\n",
            "  -0.20136017 -0.22184958]\n",
            " [-0.0010883  -0.08597124 -0.27594417  0.19537093  0.59316392  0.18402647\n",
            "   0.11257225  0.20815063 -0.15742203 -0.15555096  0.15904937 -0.21221203\n",
            "   0.06981284  0.3426515  -0.24107086 -0.04837463 -0.04425624 -0.31282311\n",
            "   0.18590683  0.01259118]\n",
            " [-0.20914651  0.11234735  0.08335259  0.10473046  0.06412649  0.04532105\n",
            "   0.63621508 -0.07494565 -0.05339176  0.03477754  0.01212067 -0.04538061\n",
            "   0.04457447  0.0151516   0.4596448   0.25910986 -0.14241527 -0.1041209\n",
            "  -0.18193612  0.3975535 ]\n",
            " [-0.11470803  0.29527616  0.03195237  0.28305864 -0.29280644 -0.35480146\n",
            "  -0.05972631 -0.16054494 -0.35231833 -0.10014786  0.14784816 -0.49239748\n",
            "   0.07721151  0.07996008  0.00092984  0.22590344 -0.03335526  0.03010231\n",
            "   0.25758323 -0.21753356]\n",
            " [ 0.00704482  0.08047817  0.13827934  0.0318194  -0.26615024 -0.07890492\n",
            "  -0.13778125 -0.09349751 -0.26889437 -0.19497051 -0.01211459  0.18455908\n",
            "   0.0785367   0.06762608 -0.04555116 -0.32899747  0.3440822  -0.54475664\n",
            "  -0.008211    0.43330216]\n",
            " [-0.12742121 -0.20441992  0.01466966 -0.04863116 -0.07261997  0.1162919\n",
            "   0.03305213 -0.41009002 -0.01570816  0.07214675  0.35508405 -0.12259613\n",
            "  -0.07118959 -0.16000348 -0.36216427 -0.22445505 -0.36916767  0.21689861\n",
            "   0.17885549  0.4209927 ]\n",
            " [-0.40490435  0.14458976  0.1456825  -0.33922928  0.16964282  0.07837634\n",
            "  -0.39586633  0.0999762   0.18393357 -0.294384   -0.07608234 -0.34078796\n",
            "   0.33888191 -0.16123568  0.07635192  0.03859285 -0.17144019 -0.08875795\n",
            "  -0.18759415  0.11909154]\n",
            " [ 0.2111115  -0.20857508  0.15452861 -0.27898007  0.04612001 -0.08135666\n",
            "   0.02652998  0.36698247 -0.34041507 -0.03697732  0.03093004  0.00149967\n",
            "  -0.05850254 -0.39910564 -0.18493061  0.50142312  0.08386556 -0.02234549\n",
            "   0.20529545  0.22332374]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct the user matrix U from the predicted vectors\n",
        "user_matrix = predicted_vectors\n",
        "\n",
        "print(\"Predicted User Matrix (U):\")\n",
        "print(user_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVYBfZVouM6U",
        "outputId": "b591aa9a-5e5a-4f65-fa99-35fa6d7d973a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted User Matrix (U):\n",
            "[[ 0.26214312  0.31447072  0.21926704  0.06828328  0.36597923 -0.32706133\n",
            "   0.01740762 -0.17508963  0.00932005  0.25326776 -0.24626782  0.05392308\n",
            "   0.26720482 -0.0677071  -0.15070903 -0.12812403 -0.05624088  0.0937004\n",
            "   0.0773148   0.13636852]\n",
            " [ 0.2988717   0.37362916 -0.03710823 -0.2393694   0.1257727  -0.08460552\n",
            "   0.11659949 -0.03828165 -0.4096093  -0.31565502  0.14800998  0.03362842\n",
            "  -0.21852727  0.03934312  0.00136865 -0.20681878 -0.11225885  0.25037454\n",
            "  -0.40808074 -0.06479491]\n",
            " [-0.02384534 -0.08115311 -0.12019273 -0.02716026  0.13575714 -0.1078049\n",
            "  -0.03070632 -0.55595845  0.20297784 -0.02030535 -0.12358828 -0.1628006\n",
            "  -0.30450425 -0.05924576 -0.25241232  0.34784454  0.30347502 -0.21949548\n",
            "  -0.32584986  0.01149472]\n",
            " [ 0.57616634  0.3966355  -0.04100484 -0.01219532 -0.10612325  0.15055724\n",
            "  -0.0389123  -0.11218404  0.40937365 -0.29186731 -0.12411854  0.02263131\n",
            "  -0.0494998   0.10799864  0.01359851  0.20857267 -0.25195387 -0.07552545\n",
            "   0.3355724   0.19294902]\n",
            " [ 0.05227133 -0.05102836  0.05878373  0.21474701 -0.20414751  0.05819712\n",
            "   0.00143897  0.24605861 -0.01815223 -0.03748325 -0.12405359  0.00810337\n",
            "   0.21396166  0.29270691 -0.44639974  0.20463856 -0.08442276  0.23541884\n",
            "  -0.48424513  0.19686704]\n",
            " [-0.02984178  0.06299135  0.38816177 -0.0804654   0.07658033  0.38335557\n",
            "   0.13813283 -0.33785313 -0.09201594 -0.08295014  0.12498914  0.07853818\n",
            "   0.16618149  0.13269409 -0.08902181  0.13999395  0.33710504  0.1155003\n",
            "   0.10973271 -0.25658001]\n",
            " [ 0.02724602 -0.11911783  0.092197    0.01999174  0.05382917 -0.26906302\n",
            "   0.09019586  0.2204855   0.46498154 -0.18663462  0.29217117 -0.14881492\n",
            "  -0.04828113  0.14195919  0.07994543 -0.0867965   0.46505156  0.31524785\n",
            "   0.08810398  0.23979107]\n",
            " [-0.20274261  0.64594709 -0.0338174   0.14934175  0.09160375  0.13254273\n",
            "  -0.33232586  0.17624801  0.0473692   0.26026039  0.33811906  0.20754703\n",
            "  -0.20678329 -0.08447187 -0.05185464  0.18285879  0.09638217  0.01514594\n",
            "  -0.05619885  0.15752292]\n",
            " [ 0.41092565  0.14989445 -0.10101126 -0.21133813 -0.15149339  0.02402709\n",
            "   0.24018573  0.05066218  0.19264203  0.28992186  0.31914238 -0.23175064\n",
            "   0.33148364 -0.08331326 -0.10257576 -0.05729262  0.06639072 -0.28046791\n",
            "  -0.20372344 -0.12793045]\n",
            " [-0.11077208  0.11638717 -0.40323928  0.06544766  0.01511826  0.03715859\n",
            "   0.11154816 -0.17073295 -0.06898584 -0.19891056 -0.0334414   0.20989602\n",
            "   0.41899094 -0.29397734 -0.03874528  0.04910612  0.28908478  0.27031919\n",
            "   0.08594705  0.0428269 ]\n",
            " [-0.47444962  0.33502744  0.04085961 -0.1347174  -0.10410093 -0.10460724\n",
            "   0.49994466  0.22820945  0.21063516 -0.09070739 -0.12994436  0.11101008\n",
            "  -0.14360008 -0.0693753  -0.44520886 -0.11542962 -0.02917874 -0.12334745\n",
            "   0.1729182  -0.18392292]\n",
            " [-0.1228544  -0.1938112   0.00394187 -0.10758737  0.028706   -0.31817081\n",
            "  -0.09432503 -0.16018173  0.09014113 -0.09767558  0.30684089  0.45007948\n",
            "   0.18786411  0.23508911  0.0035837   0.28563184 -0.28544197 -0.17792301\n",
            "  -0.00926161 -0.13524371]\n",
            " [ 0.16843932 -0.11412452  0.18133272  0.39584805  0.04934147  0.00366351\n",
            "   0.06758749  0.04592368  0.16258732 -0.27083604  0.16796213  0.03927726\n",
            "  -0.00507925 -0.48043322 -0.02728067 -0.09165791 -0.14917381 -0.19025288\n",
            "  -0.20298156 -0.22225807]\n",
            " [-0.00127491 -0.09922727 -0.1976267   0.14538936  0.46350023  0.14538764\n",
            "   0.1240511   0.22727563 -0.16938149 -0.12920888  0.13449446 -0.18552484\n",
            "   0.06189608  0.30871051 -0.23148044 -0.04664759 -0.04504606 -0.30999494\n",
            "   0.18740378  0.01261437]\n",
            " [-0.24500857  0.12967034  0.05969576  0.07793736  0.05010865  0.03580528\n",
            "   0.70108912 -0.0818317  -0.05744797  0.02888807  0.01024941 -0.03967367\n",
            "   0.03951974  0.01365077  0.44135895  0.24985933 -0.14495687 -0.10317957\n",
            "  -0.1834011   0.39828551]\n",
            " [-0.13437686  0.3408052   0.02288376  0.210644   -0.22879991 -0.28030611\n",
            "  -0.06581653 -0.1752959  -0.3790842  -0.08318812  0.12502255 -0.43047495\n",
            "   0.06845574  0.07203972  0.00089285  0.21783841 -0.03395053  0.02983016\n",
            "   0.25965733 -0.21793409]\n",
            " [ 0.00825278  0.09288721  0.0990334   0.02367907 -0.20797067 -0.06233777\n",
            "  -0.15183063 -0.10208812 -0.28932246 -0.16195285 -0.01024427  0.16134945\n",
            "   0.06963065  0.06092745 -0.04373902 -0.31725186  0.35022282 -0.53983161\n",
            "  -0.00827711  0.43409999]\n",
            " [-0.14926995 -0.23593971  0.01050617 -0.03618989 -0.05674548  0.09187485\n",
            "   0.03642241 -0.44776932 -0.01690152  0.05992892  0.30026423 -0.10717879\n",
            "  -0.0631167  -0.1441545  -0.34775644 -0.21644174 -0.37575597  0.21493767\n",
            "   0.18029566  0.42176786]\n",
            " [-0.47433273  0.16688425  0.10433542 -0.25244455  0.13255946  0.06192017\n",
            "  -0.43623232  0.10916207  0.19790713 -0.24453097 -0.06433633 -0.29793142\n",
            "   0.30045277 -0.14526465  0.07331444  0.03721504 -0.17449978 -0.08795551\n",
            "  -0.18910469  0.11931082]\n",
            " [ 0.2473105  -0.24073555  0.11067086 -0.20760885  0.03603833 -0.06427473\n",
            "   0.02923521  0.40070102 -0.36627664 -0.03071532  0.02615489  0.00131108\n",
            "  -0.05186836 -0.35957265 -0.1775736   0.48352171  0.08536226 -0.02214347\n",
            "   0.20694852  0.22373494]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the reduced rating matrix\n",
        "reduced_rating_matrix = np.dot(np.dot(user_matrix, sigma_matrix), items_matrix.T)\n",
        "\n",
        "print(\"Reduced Rating Matrix (R̂):\")\n",
        "print(reduced_rating_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJFs4fUFuRAR",
        "outputId": "a0e920c1-ebee-4f83-ac32-a2c29ef43e97"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reduced Rating Matrix (R̂):\n",
            "[[ 7.71636160e-01  9.00192139e-02 -4.96282471e-03  1.68549417e-01\n",
            "   4.35306538e-03  3.65378165e-03 -4.15265505e-02  4.85653586e-02\n",
            "   8.82246336e-02  7.03266960e-02 -1.08361832e-02 -5.64898462e-02\n",
            "  -2.96854295e-02 -3.17298675e-02 -2.00363355e-02  3.06626638e-02\n",
            "   3.17198396e-02  3.57839918e-02 -4.74537978e-02 -3.88530054e-02]\n",
            " [ 9.00192139e-02  9.54186912e-01 -4.79577027e-02  3.72232398e-02\n",
            "   7.93989144e-02  1.34767488e-02 -9.68380509e-02  6.62123113e-02\n",
            "   5.68970189e-02  5.17392254e-03 -4.80640770e-02 -9.42358740e-02\n",
            "   3.07846303e-02 -3.12320607e-02  3.74032653e-02  7.77038664e-02\n",
            "   2.01999984e-02 -4.16688452e-02 -1.01846503e-01 -2.58942015e-02]\n",
            " [-4.96282471e-03 -4.79577027e-02  9.73339704e-01  3.71513844e-03\n",
            "   1.43805916e-02  1.09511489e-01 -3.45065562e-03 -1.77444273e-02\n",
            "   2.53042354e-02  7.00100208e-03 -3.98043365e-02  4.15487683e-02\n",
            "   2.78332756e-02 -7.46863099e-02  1.15432394e-02 -8.44534045e-03\n",
            "   4.75202205e-02  5.34716629e-02 -1.40221769e-03 -6.70285816e-02]\n",
            " [ 1.68549417e-01  3.72232398e-02  3.71513844e-03  1.08466188e+00\n",
            "  -3.66861620e-02 -2.44708297e-02  3.07099622e-02  7.31656644e-02\n",
            "   1.29642994e-01 -4.33257624e-02 -5.02316427e-02 -6.43799774e-03\n",
            "   2.25338008e-02 -2.64214629e-02 -2.80257469e-02  3.60675803e-03\n",
            "  -2.90744667e-02 -1.70055784e-02 -6.63175488e-02 -3.83621698e-03]\n",
            " [ 4.35306538e-03  7.93989144e-02  1.43805916e-02 -3.66861620e-02\n",
            "   8.86113269e-01 -4.77157606e-02  2.33241928e-02  1.27998212e-02\n",
            "   3.42511000e-02 -1.26062956e-02 -2.22165361e-03  1.02071095e-02\n",
            "  -2.74348121e-02  2.42219844e-02 -6.35581192e-03 -7.85047372e-02\n",
            "  -4.58604539e-02 -2.87356712e-03  3.82666332e-02  7.25216574e-02]\n",
            " [ 3.65378165e-03  1.34767488e-02  1.09511489e-01 -2.44708297e-02\n",
            "  -4.77157606e-02  7.62794220e-01 -4.79819758e-03 -2.11159441e-02\n",
            "   1.41574393e-02  1.40554785e-01  1.89526634e-02  1.54597884e-02\n",
            "  -5.55999081e-02 -2.83475296e-03 -3.54411790e-03  9.39280652e-02\n",
            "  -1.01596517e-02 -9.77141535e-03 -9.81478145e-02 -5.77908496e-02]\n",
            " [-4.15265505e-02 -9.68380509e-02 -3.45065562e-03  3.07099622e-02\n",
            "   2.33241928e-02 -4.79819758e-03  9.31747801e-01 -2.69715244e-03\n",
            "   2.39888226e-02  4.26988684e-02  1.67642878e-02 -7.81893605e-02\n",
            "  -3.26277307e-02 -1.68970883e-02 -6.97386350e-03 -1.27252540e-01\n",
            "  -3.77871675e-02 -3.06969735e-02 -1.92592144e-02 -5.55079824e-03]\n",
            " [ 4.85653586e-02  6.62123113e-02 -1.77444273e-02  7.31656644e-02\n",
            "   1.27998212e-02 -2.11159441e-02 -2.69715244e-03  1.00015279e+00\n",
            "  -2.50451640e-02  2.04708837e-02  1.01412411e-01 -3.45519579e-02\n",
            "  -7.66637484e-02 -6.25472947e-02 -2.40045653e-02  9.20609038e-02\n",
            "   5.69697972e-02 -9.08395805e-02  1.73859116e-01 -3.07008468e-02]\n",
            " [ 8.82246336e-02  5.68970189e-02  2.53042354e-02  1.29642994e-01\n",
            "   3.42511000e-02  1.41574393e-02  2.39888226e-02 -2.50451640e-02\n",
            "   8.78270706e-01 -2.97721539e-02  2.99832308e-03 -4.11986354e-02\n",
            "   1.18243579e-01  2.96275993e-02  2.16443403e-02 -3.67281181e-02\n",
            "   8.80078202e-03 -9.52235744e-02 -9.07948418e-02 -8.49449857e-03]\n",
            " [ 7.03266960e-02  5.17392254e-03  7.00100208e-03 -4.33257624e-02\n",
            "  -1.26062956e-02  1.40554785e-01  4.26988684e-02  2.04708837e-02\n",
            "  -2.97721539e-02  7.57155119e-01  4.57733110e-02 -2.84335866e-02\n",
            "  -1.91431317e-02 -7.91246188e-02  4.62854191e-02  4.53831644e-02\n",
            "   2.35035982e-02  2.40587039e-02  7.19613303e-03  1.08122654e-02]\n",
            " [-1.08361832e-02 -4.80640770e-02 -3.98043365e-02 -5.02316427e-02\n",
            "  -2.22165361e-03  1.89526634e-02  1.67642878e-02  1.01412411e-01\n",
            "   2.99832308e-03  4.57733110e-02  1.07953496e+00 -3.17730621e-02\n",
            "   6.41339780e-03  7.58693256e-02  1.34068395e-01  3.63107377e-02\n",
            "  -5.30182809e-02 -1.35836007e-02  3.62201377e-02 -8.35708015e-02]\n",
            " [-5.64898462e-02 -9.42358740e-02  4.15487683e-02 -6.43799774e-03\n",
            "   1.02071095e-02  1.54597884e-02 -7.81893605e-02 -3.45519579e-02\n",
            "  -4.11986354e-02 -2.84335866e-02 -3.17730621e-02  8.18916037e-01\n",
            "   2.45892623e-02  1.16478339e-02  2.28225354e-03 -1.31686870e-02\n",
            "  -4.33417980e-02  4.34340294e-02  3.34182500e-02 -3.72168562e-02]\n",
            " [-2.96854295e-02  3.07846303e-02  2.78332756e-02  2.25338008e-02\n",
            "  -2.74348121e-02 -5.55999081e-02 -3.26277307e-02 -7.66637484e-02\n",
            "   1.18243579e-01 -1.91431317e-02  6.41339780e-03  2.45892623e-02\n",
            "   7.58675708e-01 -1.53769595e-02 -3.69043601e-02 -9.36513223e-02\n",
            "  -4.95752004e-02 -2.02321412e-02 -4.27400563e-03  1.54343016e-02]\n",
            " [-3.17298675e-02 -3.12320607e-02 -7.46863099e-02 -2.64214629e-02\n",
            "   2.42219844e-02 -2.83475296e-03 -1.68970883e-02 -6.25472947e-02\n",
            "   2.96275993e-02 -7.91246188e-02  7.58693256e-02  1.16478339e-02\n",
            "  -1.53769595e-02  7.59246030e-01  5.27722594e-04  2.35893265e-02\n",
            "   6.93047850e-02 -6.94942457e-03 -3.12061747e-02  9.18152044e-02]\n",
            " [-2.00363355e-02  3.74032653e-02  1.15432394e-02 -2.80257469e-02\n",
            "  -6.35581192e-03 -3.54411790e-03 -6.97386350e-03 -2.40045653e-02\n",
            "   2.16443403e-02  4.62854191e-02  1.34068395e-01  2.28225354e-03\n",
            "  -3.69043601e-02  5.27722594e-04  1.07721192e+00  5.26737314e-03\n",
            "  -3.17298191e-03  3.16210601e-02 -2.06556477e-02 -1.72547050e-02]\n",
            " [ 3.06626638e-02  7.77038664e-02 -8.44534045e-03  3.60675803e-03\n",
            "  -7.85047372e-02  9.39280652e-02 -1.27252540e-01  9.20609038e-02\n",
            "  -3.67281181e-02  4.53831644e-02  3.63107377e-02 -1.31686870e-02\n",
            "  -9.36513223e-02  2.35893265e-02  5.26737314e-03  8.70935639e-01\n",
            "  -1.58083565e-03 -7.40843462e-03  4.37141205e-02  2.37475139e-03]\n",
            " [ 3.17198396e-02  2.01999984e-02  4.75202205e-02 -2.90744667e-02\n",
            "  -4.58604539e-02 -1.01596517e-02 -3.77871675e-02  5.69697972e-02\n",
            "   8.80078202e-03  2.35035982e-02 -5.30182809e-02 -4.33417980e-02\n",
            "  -4.95752004e-02  6.93047850e-02 -3.17298191e-03 -1.58083565e-03\n",
            "   9.49459508e-01  2.77483903e-03  1.13165410e-02  1.38893938e-02]\n",
            " [ 3.57839918e-02 -4.16688452e-02  5.34716629e-02 -1.70055784e-02\n",
            "  -2.87356712e-03 -9.77141535e-03 -3.06969735e-02 -9.08395805e-02\n",
            "  -9.52235744e-02  2.40587039e-02 -1.35836007e-02  4.34340294e-02\n",
            "  -2.02321412e-02 -6.94942457e-03  3.16210601e-02 -7.40843462e-03\n",
            "   2.77483903e-03  9.88708393e-01  9.92030463e-04 -3.86380335e-02]\n",
            " [-4.74537978e-02 -1.01846503e-01 -1.40221769e-03 -6.63175488e-02\n",
            "   3.82666332e-02 -9.81478145e-02 -1.92592144e-02  1.73859116e-01\n",
            "  -9.07948418e-02  7.19613303e-03  3.62201377e-02  3.34182500e-02\n",
            "  -4.27400563e-03 -3.12061747e-02 -2.06556477e-02  4.37141205e-02\n",
            "   1.13165410e-02  9.92030463e-04  9.49257707e-01 -1.12555949e-01]\n",
            " [-3.88530054e-02 -2.58942015e-02 -6.70285816e-02 -3.83621698e-03\n",
            "   7.25216574e-02 -5.77908496e-02 -5.55079824e-03 -3.07008468e-02\n",
            "  -8.49449857e-03  1.08122654e-02 -8.35708015e-02 -3.72168562e-02\n",
            "   1.54343016e-02  9.18152044e-02 -1.72547050e-02  2.37475139e-03\n",
            "   1.38893938e-02 -3.86380335e-02 -1.12555949e-01  9.75069879e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the missing ratings for the target items (I1 and I2)\n",
        "predicted_ratings_I1 = reduced_rating_matrix[:, df.columns.get_loc(I1)]\n",
        "predicted_ratings_I2 = reduced_rating_matrix[:, df.columns.get_loc(I2)]\n",
        "\n",
        "print(f\"Predicted Ratings for {I1}:\")\n",
        "print(predicted_ratings_I1)\n",
        "\n",
        "print(f\"Predicted Ratings for {I2}:\")\n",
        "print(predicted_ratings_I2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LMfYFMKuUMx",
        "outputId": "7c1eba9b-4cc1-4425-aa43-32342ba9e0d7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Ratings for Product_11:\n",
            "[-0.01083618 -0.04806408 -0.03980434 -0.05023164 -0.00222165  0.01895266\n",
            "  0.01676429  0.10141241  0.00299832  0.04577331  1.07953496 -0.03177306\n",
            "  0.0064134   0.07586933  0.1340684   0.03631074 -0.05301828 -0.0135836\n",
            "  0.03622014 -0.0835708 ]\n",
            "Predicted Ratings for Product_8:\n",
            "[ 0.04856536  0.06621231 -0.01774443  0.07316566  0.01279982 -0.02111594\n",
            " -0.00269715  1.00015279 -0.02504516  0.02047088  0.10141241 -0.03455196\n",
            " -0.07666375 -0.06254729 -0.02400457  0.0920609   0.0569698  -0.09083958\n",
            "  0.17385912 -0.03070085]\n"
          ]
        }
      ]
    }
  ]
}